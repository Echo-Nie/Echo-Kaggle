{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4109f3d",
   "metadata": {
    "papermill": {
     "duration": 0.007251,
     "end_time": "2025-06-04T13:55:47.103166",
     "exception": false,
     "start_time": "2025-06-04T13:55:47.095915",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"color: #6cb4e4;  text-align: center;  padding: 0.25em;  border-top: solid 2.5px #6cb4e4;  border-bottom: solid 2.5px #6cb4e4;  background: -webkit-repeating-linear-gradient(-45deg, #f0f8ff, #f0f8ff 3px,#e9f4ff 3px, #e9f4ff 7px);  background: repeating-linear-gradient(-45deg, #f0f8ff, #f0f8ff 3px,#e9f4ff 3px, #e9f4ff 7px);height:45px;\">\n",
    "<b>\n",
    "《《《Submission1(nfnet)》》》\n",
    "</b></h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1ca3ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:55:47.117877Z",
     "iopub.status.busy": "2025-06-04T13:55:47.117076Z",
     "iopub.status.idle": "2025-06-04T13:56:08.450980Z",
     "shell.execute_reply": "2025-06-04T13:56:08.450015Z"
    },
    "papermill": {
     "duration": 21.342855,
     "end_time": "2025-06-04T13:56:08.452776",
     "exception": false,
     "start_time": "2025-06-04T13:55:47.109921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np  # 导入数值计算库\n",
    "import torchaudio.transforms as AT  # 导入音频转换模块\n",
    "import concurrent.futures  # 导入并行处理模块\n",
    "import os  # 导入操作系统接口模块\n",
    "import gc  # 导入垃圾收集模块\n",
    "import warnings  # 导入警告控制模块\n",
    "import logging  # 导入日志模块\n",
    "import time  # 导入时间相关模块\n",
    "import pandas as pd  # 导入数据处理库\n",
    "import soundfile as sf  # 导入音频文件读写模块\n",
    "import torch  # 导入PyTorch深度学习框架\n",
    "import torch.nn as nn  # 导入神经网络模块\n",
    "import torch.nn.functional as F  # 导入函数式接口\n",
    "import timm  # 导入预训练模型库\n",
    "from glob import glob  # 导入文件路径匹配模块\n",
    "import torchaudio  # 导入音频处理库\n",
    "import random  # 导入随机数模块\n",
    "import itertools  # 导入迭代器工具\n",
    "import concurrent.futures  # 导入并行处理模块\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # 忽略警告信息\n",
    "logging.basicConfig(level=logging.ERROR)  # 设置日志级别为ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55394b5e",
   "metadata": {
    "papermill": {
     "duration": 0.005624,
     "end_time": "2025-06-04T13:56:08.464641",
     "exception": false,
     "start_time": "2025-06-04T13:56:08.459017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🐦 BirdCLEF 2025: 加权混合推理 (LB 0.878)\n",
    "\n",
    "## 🧠 概述\n",
    "\n",
    "本notebook使用**加权混合**方法在公共排行榜上获得了**0.878**的分数。\n",
    "\n",
    "## 🧩 使用的模型\n",
    "\n",
    "最终预测基于以下公共模型的集成：\n",
    "\n",
    "- 📘 **[Bird2025 | 单一SED模型推理 [LB 0.857]](https://www.kaggle.com/code/i2nfinit3y/bird2025-single-sed-model-inference-lb-0-857)**  \n",
    "  作者：[I2nfinit3y](https://www.kaggle.com/i2nfinit3y)  \n",
    "  一个强大的单一SED模型，作为集成组件之一的基础。\n",
    "\n",
    "- 🧪 **[低排名预测的幂调整后处理](https://www.kaggle.com/code/myso1987/post-processing-with-power-adjustment-for-low-rank)**  \n",
    "  作者：[MYSO](https://www.kaggle.com/myso1987)  \n",
    "  该notebook引入了一种巧妙的后处理技术，通过幂变换提升低置信度预测。\n",
    "\n",
    "- 🔗 **[Bird25 | 加权混合 | nfnet + convnextv2 | LB.860](https://www.kaggle.com/code/hideyukizushi/bird25-weightedblend-nfnet-convnextv2-lb-860)**  \n",
    "  作者：[yukiZ](https://www.kaggle.com/hideyukizushi)  \n",
    "  提供了用于组合模型输出的核心混合逻辑。\n",
    "\n",
    "## ⚖️ 加权混合策略\n",
    "\n",
    "我们使用两个模型输出的加权平均值，具体如下：\n",
    "\n",
    "- **nfnet**: 25%\n",
    "- **seresnext**: 75%\n",
    "\n",
    "虽然这种混合方法在排行榜上获得了高分，但它可能过拟合到公共测试集 — 这是2022年至2024年BirdCLEF竞赛中常见的模式。评估结果时请考虑这一点。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce9bbdb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:08.478054Z",
     "iopub.status.busy": "2025-06-04T13:56:08.477527Z",
     "iopub.status.idle": "2025-06-04T13:56:08.570418Z",
     "shell.execute_reply": "2025-06-04T13:56:08.569220Z"
    },
    "papermill": {
     "duration": 0.101676,
     "end_time": "2025-06-04T13:56:08.572140",
     "exception": false,
     "start_time": "2025-06-04T13:56:08.470464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug mode: True\n",
      "Number of test soundscapes: 8\n"
     ]
    }
   ],
   "source": [
    "test_audio_dir = '../input/birdclef-2025/test_soundscapes/'  # 设置测试音频文件目录路径\n",
    "file_list = [f for f in sorted(os.listdir(test_audio_dir))]  # 获取目录中所有文件的排序列表\n",
    "file_list = [file.split('.')[0] for file in file_list if file.endswith('.ogg')]  # 提取所有.ogg文件的文件名（不含扩展名）\n",
    "\n",
    "debug = False  # 初始化调试模式为关闭\n",
    "if len(file_list) == 0:  # 如果测试目录为空\n",
    "    debug = True  # 开启调试模式\n",
    "    debug_st_num = 5  # 设置调试起始样本编号\n",
    "    debug_num = 8  # 设置调试样本数量\n",
    "    test_audio_dir = '../input/birdclef-2025/train_soundscapes/'  # 改用训练集音频文件作为测试\n",
    "    file_list = [f for f in sorted(os.listdir(test_audio_dir))]  # 获取训练集目录中所有文件\n",
    "    file_list = [file.split('.')[0] for file in file_list if file.endswith('.ogg')]  # 提取所有.ogg文件的文件名\n",
    "    file_list = file_list[debug_st_num:debug_st_num+debug_num]  # 选取指定范围的文件进行调试\n",
    "\n",
    "print('Debug mode:', debug)  # 打印当前调试模式状态\n",
    "print('Number of test soundscapes:', len(file_list))  # 打印测试音频文件数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a9e535d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:08.586005Z",
     "iopub.status.busy": "2025-06-04T13:56:08.585664Z",
     "iopub.status.idle": "2025-06-04T13:56:08.592061Z",
     "shell.execute_reply": "2025-06-04T13:56:08.591059Z"
    },
    "papermill": {
     "duration": 0.01535,
     "end_time": "2025-06-04T13:56:08.593840",
     "exception": false,
     "start_time": "2025-06-04T13:56:08.578490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adaptive_power(p, top_k=30, min_exp=1.5, max_exp=3.0, inplace=True):\n",
    "    if not inplace:  # 如果不进行原地操作\n",
    "        p = p.copy()  # 创建输入数组的副本\n",
    "    col_max = p.max(axis=0)  # 计算每列的最大值\n",
    "    ranks = np.argsort(-col_max)  # 根据列最大值降序排序获取索引\n",
    "    exps = np.linspace(max_exp, min_exp, len(col_max))  # 创建线性递减的指数值数组\n",
    "    for i, col in enumerate(ranks[top_k:]):  # 遍历排名在top_k之后的列\n",
    "        p[:, col] = p[:, col] ** exps[i]  # 对每列应用不同的幂次变换\n",
    "    return p  # 返回处理后的数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "430d2e3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:08.607783Z",
     "iopub.status.busy": "2025-06-04T13:56:08.607432Z",
     "iopub.status.idle": "2025-06-04T13:56:08.666204Z",
     "shell.execute_reply": "2025-06-04T13:56:08.664921Z"
    },
    "papermill": {
     "duration": 0.067886,
     "end_time": "2025-06-04T13:56:08.668118",
     "exception": false,
     "start_time": "2025-06-04T13:56:08.600232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "wav_sec = 5  # 设置每个音频片段的时长为5秒\n",
    "sample_rate = 32000  # 设置采样率为32kHz\n",
    "min_segment = sample_rate*wav_sec  # 计算最小音频片段的样本数\n",
    "\n",
    "class_labels = sorted(os.listdir('../input/birdclef-2025/train_audio/'))  # 获取并排序所有鸟类标签\n",
    "\n",
    "n_fft=1024  # 设置快速傅里叶变换的窗口大小\n",
    "win_length=1024  # 设置窗口长度\n",
    "hop_length=512  # 设置窗口移动步长\n",
    "f_min=40  # 设置最小频率\n",
    "f_max=16000  # 设置最大频率\n",
    "n_mels=128  # 设置梅尔频谱的频段数\n",
    "\n",
    "mel_spectrogram = AT.MelSpectrogram(  # 创建梅尔频谱转换器\n",
    "    sample_rate=sample_rate,  # 指定采样率\n",
    "    n_fft=n_fft,  # 指定FFT窗口大小\n",
    "    win_length=win_length,  # 指定窗口长度\n",
    "    hop_length=hop_length,  # 指定窗口移动步长\n",
    "    center=True,  # 启用中心填充\n",
    "    f_min=f_min,  # 指定最小频率\n",
    "    f_max=f_max,  # 指定最大频率\n",
    "    pad_mode=\"reflect\",  # 使用反射填充模式\n",
    "    power=2.0,  # 使用功率谱\n",
    "    norm='slaney',  # 使用Slaney归一化\n",
    "    n_mels=n_mels,  # 指定梅尔频段数\n",
    "    mel_scale=\"htk\",  # 使用HTK梅尔尺度\n",
    ")\n",
    "\n",
    "def normalize_std(spec, eps=1e-6):  # 定义标准化函数\n",
    "    mean = torch.mean(spec)  # 计算均值\n",
    "    std = torch.std(spec)  # 计算标准差\n",
    "    return torch.where(std == 0, spec-mean, (spec - mean) / (std+eps))  # 标准化，并处理标准差为0的情况\n",
    "\n",
    "def audio_to_mel(filepath=None):  # 定义音频转梅尔频谱的函数\n",
    "    waveform, sample_rate = torchaudio.load(filepath,backend=\"soundfile\")  # 加载音频文件\n",
    "    len_wav = waveform.shape[1]  # 获取音频长度\n",
    "    waveform = waveform[0,:].reshape(1, len_wav)  # 将立体声转为单声道\n",
    "    PREDS = []  # 初始化预测结果列表\n",
    "    for i in range(12):  # 对每个5秒片段进行处理\n",
    "        waveform2 = waveform[:,i*sample_rate*5:i*sample_rate*5+sample_rate*5]  # 提取5秒片段\n",
    "        melspec = mel_spectrogram(waveform2)  # 转换为梅尔频谱\n",
    "        melspec = torch.log(melspec+1e-6)  # 对频谱取对数\n",
    "        melspec = normalize_std(melspec)  # 标准化频谱\n",
    "        melspec = torch.unsqueeze(melspec, dim=0)  # 增加批次维度\n",
    "        \n",
    "        PREDS.append(melspec)  # 添加到结果列表\n",
    "    return torch.vstack(PREDS)  # 垂直堆叠所有频谱并返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46c5c1b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:08.684183Z",
     "iopub.status.busy": "2025-06-04T13:56:08.683838Z",
     "iopub.status.idle": "2025-06-04T13:56:08.702303Z",
     "shell.execute_reply": "2025-06-04T13:56:08.701307Z"
    },
    "papermill": {
     "duration": 0.027919,
     "end_time": "2025-06-04T13:56:08.703973",
     "exception": false,
     "start_time": "2025-06-04T13:56:08.676054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_layer(layer):  # 初始化网络层函数\n",
    "    nn.init.xavier_uniform_(layer.weight)  # 使用Xavier均匀分布初始化权重\n",
    "    if hasattr(layer, \"bias\"):  # 如果层有偏置参数\n",
    "        if layer.bias is not None:  # 如果偏置不为None\n",
    "            layer.bias.data.fill_(0.)  # 将偏置初始化为0\n",
    "\n",
    "\n",
    "def init_bn(bn):  # 初始化批归一化层函数\n",
    "    bn.bias.data.fill_(0.)  # 批归一化偏置初始化为0\n",
    "    bn.weight.data.fill_(1.0)  # 批归一化权重初始化为1\n",
    "\n",
    "\n",
    "def init_weights(model):  # 根据层类型初始化模型权重的函数\n",
    "    classname = model.__class__.__name__  # 获取模型类名\n",
    "    if classname.find(\"Conv2d\") != -1:  # 如果是卷积层\n",
    "        nn.init.xavier_uniform_(model.weight, gain=np.sqrt(2))  # 使用Xavier初始化权重\n",
    "        model.bias.data.fill_(0)  # 偏置初始化为0\n",
    "    elif classname.find(\"BatchNorm\") != -1:  # 如果是批归一化层\n",
    "        model.weight.data.normal_(1.0, 0.02)  # 权重初始化为均值1.0，标准差0.02的正态分布\n",
    "        model.bias.data.fill_(0)  # 偏置初始化为0\n",
    "    elif classname.find(\"GRU\") != -1:  # 如果是GRU层\n",
    "        for weight in model.parameters():  # 遍历所有参数\n",
    "            if len(weight.size()) > 1:  # 如果参数维度大于1\n",
    "                nn.init.orghogonal_(weight.data)  # 使用正交初始化\n",
    "    elif classname.find(\"Linear\") != -1:  # 如果是线性层\n",
    "        model.weight.data.normal_(0, 0.01)  # 权重初始化为均值0，标准差0.01的正态分布\n",
    "        model.bias.data.zero_()  # 偏置初始化为0\n",
    "\n",
    "\n",
    "def interpolate(x, ratio):  # 时间维度插值函数\n",
    "    (batch_size, time_steps, classes_num) = x.shape  # 获取输入形状\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)  # 在时间维度重复\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)  # 重塑形状\n",
    "    return upsampled  # 返回上采样结果\n",
    "\n",
    "\n",
    "def pad_framewise_output(framewise_output, frames_num):  # 帧级输出填充函数\n",
    "    output = F.interpolate(  # 使用双线性插值\n",
    "        framewise_output.unsqueeze(1),  # 增加维度\n",
    "        size=(frames_num, framewise_output.size(2)),  # 设置目标大小\n",
    "        align_corners=True,  # 对齐角点\n",
    "        mode=\"bilinear\").squeeze(1)  # 使用双线性插值并压缩维度\n",
    "\n",
    "    return output  # 返回填充后的输出\n",
    "\n",
    "\n",
    "class AttBlockV2(nn.Module):  # 注意力块V2定义\n",
    "    def __init__(self,\n",
    "                 in_features: int,  # 输入特征维度\n",
    "                 out_features: int,  # 输出特征维度\n",
    "                 activation=\"linear\"):  # 激活函数类型\n",
    "        super().__init__()  # 调用父类初始化\n",
    "\n",
    "        self.activation = activation  # 设置激活函数\n",
    "        self.att = nn.Conv1d(  # 注意力卷积层\n",
    "            in_channels=in_features,  # 输入通道数\n",
    "            out_channels=out_features,  # 输出通道数\n",
    "            kernel_size=1,  # 卷积核大小\n",
    "            stride=1,  # 步长\n",
    "            padding=0,  # 填充\n",
    "            bias=True)  # 使用偏置\n",
    "        self.cla = nn.Conv1d(  # 分类卷积层\n",
    "            in_channels=in_features,  # 输入通道数\n",
    "            out_channels=out_features,  # 输出通道数\n",
    "            kernel_size=1,  # 卷积核大小\n",
    "            stride=1,  # 步长\n",
    "            padding=0,  # 填充\n",
    "            bias=True)  # 使用偏置\n",
    "\n",
    "        self.init_weights()  # 初始化权重\n",
    "\n",
    "    def init_weights(self):  # 初始化权重方法\n",
    "        init_layer(self.att)  # 初始化注意力层\n",
    "        init_layer(self.cla)  # 初始化分类层\n",
    "\n",
    "    def forward(self, x):  # 前向传播\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)  # 计算归一化注意力\n",
    "        cla = self.nonlinear_transform(self.cla(x))  # 应用非线性变换到分类输出\n",
    "        x = torch.sum(norm_att * cla, dim=2)  # 计算加权和\n",
    "        return x, norm_att, cla  # 返回输出、注意力权重和分类输出\n",
    "\n",
    "    def nonlinear_transform(self, x):  # 非线性变换函数\n",
    "        if self.activation == 'linear':  # 如果是线性激活\n",
    "            return x  # 直接返回输入\n",
    "        elif self.activation == 'sigmoid':  # 如果是sigmoid激活\n",
    "            return torch.sigmoid(x)  # 应用sigmoid函数\n",
    "\n",
    "\n",
    "class TimmSED(nn.Module):  # 基于Timm的声音事件检测模型\n",
    "    def __init__(self, base_model_name: str, pretrained=False, num_classes=24, in_channels=1, n_mels=24):  # 初始化函数\n",
    "        super().__init__()  # 调用父类初始化\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(n_mels)  # 创建批归一化层\n",
    "\n",
    "        base_model = timm.create_model(  # 创建基础模型\n",
    "            base_model_name, pretrained=pretrained, in_chans=in_channels)\n",
    "        layers = list(base_model.children())[:-2]  # 提取除最后两层外的所有层\n",
    "        self.encoder = nn.Sequential(*layers)  # 创建编码器\n",
    "\n",
    "        in_features = base_model.num_features  # 获取特征维度\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features, in_features, bias=True)  # 创建全连接层\n",
    "        self.att_block2 = AttBlockV2(  # 创建注意力块\n",
    "            in_features, num_classes, activation=\"sigmoid\")\n",
    "\n",
    "        self.init_weight()  # 初始化权重\n",
    "\n",
    "    def init_weight(self):  # 初始化权重方法\n",
    "        init_bn(self.bn0)  # 初始化批归一化层\n",
    "        init_layer(self.fc1)  # 初始化全连接层\n",
    "        \n",
    "\n",
    "    def forward(self, input_data):  # 前向传播\n",
    "        x = input_data.transpose(2,3)  # 转置输入数据维度\n",
    "        x = torch.cat((x,x,x),1)  # 在通道维度复制三次\n",
    "\n",
    "        x = x.transpose(2, 3)  # 再次转置维度\n",
    "\n",
    "        x = self.encoder(x)  # 通过编码器\n",
    "        \n",
    "        x = torch.mean(x, dim=2)  # 在频率维度求平均\n",
    "\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)  # 最大池化\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)  # 平均池化\n",
    "        x = x1 + x2  # 合并池化结果\n",
    "\n",
    "        x = x.transpose(1, 2)  # 转置维度\n",
    "        x = F.relu_(self.fc1(x))  # 应用ReLU激活函数\n",
    "        x = x.transpose(1, 2)  # 再次转置维度\n",
    "\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block2(x)  # 通过注意力块\n",
    "        logit = torch.sum(norm_att * self.att_block2.cla(x), dim=2)  # 计算logit输出\n",
    "\n",
    "        output_dict = {  # 创建输出字典\n",
    "            'logit': logit,  # 保存logit\n",
    "        }\n",
    "\n",
    "        return output_dict  # 返回输出字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee33c47d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:08.718248Z",
     "iopub.status.busy": "2025-06-04T13:56:08.717142Z",
     "iopub.status.idle": "2025-06-04T13:56:08.724989Z",
     "shell.execute_reply": "2025-06-04T13:56:08.723941Z"
    },
    "papermill": {
     "duration": 0.016327,
     "end_time": "2025-06-04T13:56:08.726425",
     "exception": false,
     "start_time": "2025-06-04T13:56:08.710098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/kaggle/input/birdclef-2025-sed-models-p/sed0.pth',\n",
       " '/kaggle/input/birdclef-2025-sed-models-p/sed1.pth',\n",
       " '/kaggle/input/birdclef-2025-sed-models-p/sed2.pth']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_name='eca_nfnet_l0'  # 设置基础模型名称为ECA-NFNet-L0\n",
    "pretrained=False  # 不使用预训练权重\n",
    "in_channels=3  # 设置输入通道数为3\n",
    "\n",
    "MODELS = [f'/kaggle/input/birdclef-2025-sed-models-p/sed{i}.pth' for i in range(3)]  # 创建包含3个模型路径的列表\n",
    "\n",
    "MODELS  # 显示模型路径列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c627ee3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:08.740284Z",
     "iopub.status.busy": "2025-06-04T13:56:08.739924Z",
     "iopub.status.idle": "2025-06-04T13:56:08.748130Z",
     "shell.execute_reply": "2025-06-04T13:56:08.747003Z"
    },
    "papermill": {
     "duration": 0.017017,
     "end_time": "2025-06-04T13:56:08.749818",
     "exception": false,
     "start_time": "2025-06-04T13:56:08.732801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prediction(afile):    \n",
    "    global pred  # 使用全局预测结果字典\n",
    "    path = test_audio_dir + afile + '.ogg'  # 构建音频文件完整路径\n",
    "    with torch.inference_mode():  # 使用推理模式，不计算梯度\n",
    "        sig = audio_to_mel(path)  # 将音频转换为梅尔频谱\n",
    "        outputs = None  # 初始化输出为None\n",
    "        for model in models:  # 遍历所有模型\n",
    "            model.eval()  # 将模型设为评估模式\n",
    "            p = model(sig)  # 通过模型获取预测结果\n",
    "            p = torch.sigmoid(p['logit']).detach().cpu().numpy()  # 应用sigmoid，转为numpy数组\n",
    "            p = adaptive_power(p, top_k=30, min_exp=1.5, max_exp=3.0)  # 应用自适应幂变换\n",
    "            if outputs is None: outputs = p  # 如果是第一个模型，直接赋值\n",
    "            else: outputs += p  # 否则累加预测结果\n",
    "            \n",
    "        outputs /= len(models)  # 计算模型平均结果\n",
    "        chunks = [[] for i in range(12)]  # 初始化12个区块的列表\n",
    "        for i in range(len(chunks)):  # 遍历每个区块      \n",
    "            chunk_end_time = (i + 1) * 5  # 计算区块结束时间\n",
    "            row_id = afile + '_' + str(chunk_end_time)  # 构建行ID\n",
    "            pred['row_id'].append(row_id)  # 添加行ID到结果\n",
    "            bird_no = 0  # 初始化鸟类编号\n",
    "            for bird in class_labels:  # 遍历所有鸟类类别       \n",
    "                pred[bird].append(outputs[i,bird_no])  # 添加该鸟类的预测概率\n",
    "                bird_no += 1  # 鸟类编号加1\n",
    "        gc.collect()  # 触发垃圾回收"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fa50b3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:08.764451Z",
     "iopub.status.busy": "2025-06-04T13:56:08.764088Z",
     "iopub.status.idle": "2025-06-04T13:56:13.145479Z",
     "shell.execute_reply": "2025-06-04T13:56:13.144283Z"
    },
    "papermill": {
     "duration": 4.390174,
     "end_time": "2025-06-04T13:56:13.147106",
     "exception": false,
     "start_time": "2025-06-04T13:56:08.756932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = []  # 初始化模型列表\n",
    "for path in MODELS:  # 遍历所有模型路径\n",
    "    model = TimmSED(base_model_name=base_model_name,  # 创建TimmSED模型实例\n",
    "               pretrained=pretrained,  # 设置是否使用预训练\n",
    "               num_classes=len(class_labels),  # 设置类别数量\n",
    "               in_channels=in_channels,  # 设置输入通道数\n",
    "               n_mels=n_mels)  # 设置梅尔频谱频段数\n",
    "    model.load_state_dict(torch.load(path, weights_only=True, map_location=torch.device('cpu')))  # 加载模型权重\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    models.append(model)  # 将模型添加到列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea2b32cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:13.161065Z",
     "iopub.status.busy": "2025-06-04T13:56:13.160592Z",
     "iopub.status.idle": "2025-06-04T13:56:38.336791Z",
     "shell.execute_reply": "2025-06-04T13:56:38.335525Z"
    },
    "papermill": {
     "duration": 25.185337,
     "end_time": "2025-06-04T13:56:38.338867",
     "exception": false,
     "start_time": "2025-06-04T13:56:13.153530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.70228918393453\n"
     ]
    }
   ],
   "source": [
    "pred = {'row_id': []}  # 初始化预测结果字典，包含行ID键\n",
    "for species_code in class_labels:  # 遍历所有鸟类类别\n",
    "    pred[species_code] = []  # 为每个鸟类创建空列表\n",
    "    \n",
    "start = time.time()  # 记录开始时间\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:  # 创建线程池执行器，最大5个线程\n",
    "    _ = list(executor.map(prediction, file_list))  # 并行执行预测函数\n",
    "end_t = time.time()  # 记录结束时间\n",
    "\n",
    "if debug == True:  # 如果是调试模式\n",
    "    print(700*(end_t - start)/60/debug_num)  # 打印估计的完整数据集处理时间（分钟）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f8fa122",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:38.360939Z",
     "iopub.status.busy": "2025-06-04T13:56:38.360603Z",
     "iopub.status.idle": "2025-06-04T13:56:38.394778Z",
     "shell.execute_reply": "2025-06-04T13:56:38.393768Z"
    },
    "papermill": {
     "duration": 0.043771,
     "end_time": "2025-06-04T13:56:38.396790",
     "exception": false,
     "start_time": "2025-06-04T13:56:38.353019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(pred, columns = ['row_id'] + class_labels)  # 创建结果数据框，包含行ID和所有鸟类类别列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe73b181",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:38.411111Z",
     "iopub.status.busy": "2025-06-04T13:56:38.410155Z",
     "iopub.status.idle": "2025-06-04T13:56:39.003829Z",
     "shell.execute_reply": "2025-06-04T13:56:39.002689Z"
    },
    "papermill": {
     "duration": 0.602718,
     "end_time": "2025-06-04T13:56:39.005707",
     "exception": false,
     "start_time": "2025-06-04T13:56:38.402989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.to_csv(\"submission1.csv\", index=False)  # 保存结果为CSV文件，不包含索引列\n",
    "\n",
    "sub = pd.read_csv('submission1.csv')  # 读取保存的CSV文件\n",
    "cols = sub.columns[1:]  # 获取除行ID外的所有列名\n",
    "groups = sub['row_id'].str.rsplit('_', n=1).str[0]  # 从行ID中提取声音文件名\n",
    "groups = groups.values  # 转换为numpy数组\n",
    "for group in np.unique(groups):  # 遍历每个唯一的声音文件\n",
    "    sub_group = sub[group == groups]  # 提取当前声音文件的所有片段\n",
    "    predictions = sub_group[cols].values  # 获取预测值数组\n",
    "    new_predictions = predictions.copy()  # 创建预测值副本\n",
    "    for i in range(1, predictions.shape[0]-1):  # 处理中间片段（应用滑动窗口平滑）\n",
    "        new_predictions[i] = (predictions[i-1] * 0.2) + (predictions[i] * 0.6) + (predictions[i+1] * 0.2)  # 加权平均\n",
    "    new_predictions[0] = (predictions[0] * 0.8) + (predictions[1] * 0.2)  # 处理第一个片段\n",
    "    new_predictions[-1] = (predictions[-1] * 0.8) + (predictions[-2] * 0.2)  # 处理最后一个片段\n",
    "    sub_group[cols] = new_predictions  # 更新子组的预测值\n",
    "    sub[group == groups] = sub_group  # 将子组结果放回主数据框\n",
    "sub.to_csv(\"submission1.csv\", index=False)  # 保存平滑后的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147effdd",
   "metadata": {
    "papermill": {
     "duration": 0.005954,
     "end_time": "2025-06-04T13:56:39.018292",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.012338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"color: #6cb4e4;  text-align: center;  padding: 0.25em;  border-top: solid 2.5px #6cb4e4;  border-bottom: solid 2.5px #6cb4e4;  background: -webkit-repeating-linear-gradient(-45deg, #f0f8ff, #f0f8ff 3px,#e9f4ff 3px, #e9f4ff 7px);  background: repeating-linear-gradient(-45deg, #f0f8ff, #f0f8ff 3px,#e9f4ff 3px, #e9f4ff 7px);height:45px;\">\n",
    "<b>\n",
    "《《《submission2(seresnext)》》》\n",
    "</b></h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5151069",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.031760Z",
     "iopub.status.busy": "2025-06-04T13:56:39.031459Z",
     "iopub.status.idle": "2025-06-04T13:56:39.501435Z",
     "shell.execute_reply": "2025-06-04T13:56:39.500363Z"
    },
    "papermill": {
     "duration": 0.478661,
     "end_time": "2025-06-04T13:56:39.503051",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.024390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os  # 导入操作系统接口模块\n",
    "import gc  # 导入垃圾收集模块\n",
    "import warnings  # 导入警告控制模块\n",
    "import logging  # 导入日志模块\n",
    "import time  # 导入时间相关模块\n",
    "from pathlib import Path  # 导入路径处理模块\n",
    "import pandas as pd  # 导入数据处理库\n",
    "import soundfile as sf  # 导入音频文件读写模块\n",
    "import torch  # 导入PyTorch深度学习框架\n",
    "import torch.nn as nn  # 导入神经网络模块\n",
    "import torch.nn.functional as F  # 导入函数式接口\n",
    "import timm  # 导入预训练模型库\n",
    "from glob import glob  # 导入文件路径匹配模块\n",
    "import torchaudio  # 导入音频处理库\n",
    "import random  # 导入随机数模块\n",
    "import itertools  # 导入迭代器工具\n",
    "import concurrent.futures  # 导入并行处理模块\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # 忽略警告信息\n",
    "logging.basicConfig(level=logging.ERROR)  # 设置日志级别为ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9968aac5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.517368Z",
     "iopub.status.busy": "2025-06-04T13:56:39.516923Z",
     "iopub.status.idle": "2025-06-04T13:56:39.522940Z",
     "shell.execute_reply": "2025-06-04T13:56:39.521972Z"
    },
    "papermill": {
     "duration": 0.015008,
     "end_time": "2025-06-04T13:56:39.524583",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.509575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:  # 定义配置类\n",
    "    \n",
    "    seed = 42  # 随机种子\n",
    "    print_freq = 100  # 打印频率\n",
    "    num_workers = 4  # 数据加载器的工作线程数\n",
    "\n",
    "    stage = 'train_bce'  # 训练阶段标识\n",
    "\n",
    "    train_datadir = '/kaggle/input/birdclef-2025/train_audio'  # 训练音频目录\n",
    "    train_csv = '/kaggle/input/birdclef-2025/train.csv'  # 训练CSV文件路径\n",
    "    test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'  # 测试声音景观目录\n",
    "    submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'  # 提交样例文件\n",
    "    taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'  # 分类学CSV文件路径\n",
    "    model_files = ['/kaggle/input/bird2025-sed-ckpt/sedmodel.pth'  # 模型文件路径\n",
    "                  ]\n",
    " \n",
    "    model_name = 'seresnext26t_32x4d'  # 模型名称\n",
    "    pretrained = False  # 是否使用预训练权重\n",
    "    in_channels = 1  # 输入通道数\n",
    "\n",
    "    \n",
    "    SR = 32000  # 采样率\n",
    "    target_duration = 5  # 目标音频持续时间（秒）\n",
    "    train_duration = 10  # 训练音频持续时间（秒）\n",
    "    \n",
    "    \n",
    "    device = 'cpu'  # 计算设备\n",
    "\n",
    "cfg = CFG()  # 创建配置对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc09ee15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.538726Z",
     "iopub.status.busy": "2025-06-04T13:56:39.538280Z",
     "iopub.status.idle": "2025-06-04T13:56:39.550605Z",
     "shell.execute_reply": "2025-06-04T13:56:39.549476Z"
    },
    "papermill": {
     "duration": 0.021381,
     "end_time": "2025-06-04T13:56:39.552471",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.531090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading taxonomy data...\n",
      "Number of classes: 206\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using device: {cfg.device}\")  # 打印所使用的计算设备\n",
    "print(f\"Loading taxonomy data...\")  # 打印加载分类数据的信息\n",
    "taxonomy_df = pd.read_csv(cfg.taxonomy_csv)  # 读取鸟类分类数据\n",
    "species_ids = taxonomy_df['primary_label'].tolist()  # 提取所有鸟类ID列表\n",
    "num_classes = len(species_ids)  # 计算鸟类类别数量\n",
    "print(f\"Number of classes: {num_classes}\")  # 打印类别数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3fd51d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.566606Z",
     "iopub.status.busy": "2025-06-04T13:56:39.566239Z",
     "iopub.status.idle": "2025-06-04T13:56:39.579710Z",
     "shell.execute_reply": "2025-06-04T13:56:39.578797Z"
    },
    "papermill": {
     "duration": 0.022438,
     "end_time": "2025-06-04T13:56:39.581389",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.558951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):  # 定义设置随机种子的函数\n",
    "    \"\"\"\n",
    "    设置随机种子以确保结果可重现\n",
    "    \"\"\"\n",
    "    random.seed(seed)  # 设置Python随机模块的种子\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)  # 设置Python哈希种子\n",
    "    np.random.seed(seed)  # 设置NumPy随机种子\n",
    "    torch.manual_seed(seed)  # 设置PyTorch CPU随机种子\n",
    "    torch.cuda.manual_seed(seed)  # 设置PyTorch单GPU随机种子\n",
    "    torch.cuda.manual_seed_all(seed)  # 设置PyTorch多GPU随机种子\n",
    "    torch.backends.cudnn.deterministic = True  # 使cudnn卷积操作确定性\n",
    "    torch.backends.cudnn.benchmark = False  # 禁用cudnn基准测试\n",
    "\n",
    "set_seed(cfg.seed)  # 使用配置中的种子初始化随机性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d97e381",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.595707Z",
     "iopub.status.busy": "2025-06-04T13:56:39.595341Z",
     "iopub.status.idle": "2025-06-04T13:56:39.605390Z",
     "shell.execute_reply": "2025-06-04T13:56:39.604427Z"
    },
    "papermill": {
     "duration": 0.019114,
     "end_time": "2025-06-04T13:56:39.607090",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.587976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttBlockV2(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, activation=\"linear\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == \"linear\":\n",
    "            return x\n",
    "        elif self.activation == \"sigmoid\":\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.0)\n",
    "\n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.0)\n",
    "    bn.weight.data.fill_(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65d6c282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.622132Z",
     "iopub.status.busy": "2025-06-04T13:56:39.621775Z",
     "iopub.status.idle": "2025-06-04T13:56:39.643285Z",
     "shell.execute_reply": "2025-06-04T13:56:39.642156Z"
    },
    "papermill": {
     "duration": 0.031308,
     "end_time": "2025-06-04T13:56:39.645163",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.613855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BirdCLEFModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        taxonomy_df = pd.read_csv('/kaggle/input/birdclef-2025/taxonomy.csv')\n",
    "        self.num_classes = len(taxonomy_df)\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(cfg['n_mels'])\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            cfg['model_name'],\n",
    "            pretrained=False,\n",
    "            in_chans=cfg['in_channels'],\n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.2,\n",
    "        )\n",
    "\n",
    "        layers = list(self.backbone.children())[:-2]\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "        \n",
    "        if \"efficientnet\" in self.cfg['model_name']:\n",
    "            backbone_out = self.backbone.classifier.in_features\n",
    "        elif \"eca\" in self.cfg['model_name']:\n",
    "            backbone_out = self.backbone.head.fc.in_features\n",
    "        elif \"res\" in self.cfg['model_name']:\n",
    "            backbone_out = self.backbone.fc.in_features\n",
    "        else:\n",
    "            backbone_out = self.backbone.num_features\n",
    "            \n",
    "        \n",
    "        self.fc1 = nn.Linear(backbone_out, backbone_out, bias=True)\n",
    "        self.att_block = AttBlockV2(backbone_out, self.num_classes, activation=\"sigmoid\")\n",
    "\n",
    "        self.melspec_transform = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=self.cfg['SR'],\n",
    "            hop_length=self.cfg['hop_length'],\n",
    "            n_mels=self.cfg['n_mels'],\n",
    "            f_min=self.cfg['f_min'],\n",
    "            f_max=self.cfg['f_max'],\n",
    "            n_fft=self.cfg['n_fft'],\n",
    "            pad_mode=\"constant\",\n",
    "            norm=\"slaney\",\n",
    "            onesided=True,\n",
    "            mel_scale=\"htk\",\n",
    "        )\n",
    "        if self.cfg['device'] == \"cuda\":\n",
    "            self.melspec_transform = self.melspec_transform.cuda()\n",
    "        else:\n",
    "            self.melspec_transform = self.melspec_transform.cpu()\n",
    "\n",
    "        self.db_transform = torchaudio.transforms.AmplitudeToDB(\n",
    "            stype=\"power\", top_db=80\n",
    "        )\n",
    "\n",
    "\n",
    "    def extract_feature(self,x):\n",
    "        x = x.permute((0, 1, 3, 2))\n",
    "        frames_num = x.shape[2]\n",
    "        \n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "        \n",
    "        # if self.training:\n",
    "        #    x = self.spec_augmenter(x)\n",
    "        \n",
    "        x = x.transpose(2, 3)\n",
    "        # (batch_size, channels, freq, frames)\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        # (batch_size, channels, frames)\n",
    "        x = torch.mean(x, dim=2)\n",
    "        \n",
    "        # channel smoothing\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "        \n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return x, frames_num\n",
    "        \n",
    "    @torch.cuda.amp.autocast(enabled=False)\n",
    "    def transform_to_spec(self, audio):\n",
    "\n",
    "        audio = audio.float()\n",
    "        \n",
    "        spec = self.melspec_transform(audio)\n",
    "        spec = self.db_transform(spec)\n",
    "\n",
    "        if self.cfg['normal'] == 80:\n",
    "            spec = (spec + 80) / 80\n",
    "        elif self.cfg['normal'] == 255:\n",
    "            spec = spec / 255\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "                \n",
    "        if self.cfg['in_channels'] == 3:\n",
    "            spec = image_delta(spec)\n",
    "        \n",
    "        return spec\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = self.transform_to_spec(x)\n",
    "\n",
    "        x, frames_num = self.extract_feature(x)\n",
    "        \n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n",
    "        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        return torch.logit(clipwise_output)\n",
    "\n",
    "    def infer(self, x, tta_delta=2):\n",
    "        with torch.no_grad():\n",
    "            x = self.transform_to_spec(x)\n",
    "        x,_ = self.extract_feature(x)\n",
    "        time_att = torch.tanh(self.att_block.att(x))\n",
    "        feat_time = x.size(-1)\n",
    "        start = (\n",
    "            feat_time / 2 - feat_time * (self.cfg['infer_duration'] / self.cfg['duration_train']) / 2\n",
    "        )\n",
    "        end = start + feat_time * (self.cfg['infer_duration'] / self.cfg['duration_train'])\n",
    "        start = int(start)\n",
    "        end = int(end)\n",
    "        pred = self.attention_infer(start,end,x,time_att)\n",
    "\n",
    "        start_minus = max(0, start-tta_delta)\n",
    "        end_minus=end-tta_delta\n",
    "        pred_minus = self.attention_infer(start_minus,end_minus,x,time_att)\n",
    "\n",
    "        start_plus = start+tta_delta\n",
    "        end_plus=min(feat_time, end+tta_delta)\n",
    "        pred_plus = self.attention_infer(start_plus,end_plus,x,time_att)\n",
    "\n",
    "        pred = 0.5*pred + 0.25*pred_minus + 0.25*pred_plus\n",
    "        return pred\n",
    "        \n",
    "    def attention_infer(self,start,end,x,time_att):\n",
    "        feat = x[:, :, start:end]\n",
    "        # att = torch.softmax(time_att[:, :, start:end], dim=-1)\n",
    "        #             print(feat_time, start, end)\n",
    "        #             print(att_a.sum(), att.sum(), time_att.shape)\n",
    "        framewise_pred = torch.sigmoid(self.att_block.cla(feat))\n",
    "        framewise_pred_max = framewise_pred.max(dim=2)[0]\n",
    "        # clipwise_output = torch.sum(framewise_pred * att, dim=-1)\n",
    "        #logits = torch.sum(\n",
    "        #    self.att_block.cla(feat) * att,\n",
    "        #    dim=-1,\n",
    "        #)\n",
    "\n",
    "        # return clipwise_output\n",
    "        return framewise_pred_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ba6ddcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.659552Z",
     "iopub.status.busy": "2025-06-04T13:56:39.659186Z",
     "iopub.status.idle": "2025-06-04T13:56:39.668906Z",
     "shell.execute_reply": "2025-06-04T13:56:39.667745Z"
    },
    "papermill": {
     "duration": 0.019029,
     "end_time": "2025-06-04T13:56:39.670693",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.651664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_sample(path, cfg):\n",
    "    audio, orig_sr = sf.read(path, dtype=\"float32\")\n",
    "    seconds = []\n",
    "    audio_length = cfg.SR * cfg.target_duration\n",
    "    step = audio_length\n",
    "    for i in range(audio_length, len(audio) + step, step):\n",
    "        start = max(0, i - audio_length)\n",
    "        end = start + audio_length\n",
    "        if end > len(audio):\n",
    "            pass\n",
    "        else:\n",
    "            seconds.append(int(end/cfg.SR))\n",
    "\n",
    "    audio = np.concatenate([audio,audio,audio])\n",
    "    audios = []\n",
    "    for i,second in enumerate(seconds):\n",
    "        end_seconds = int(second)\n",
    "        start_seconds = int(end_seconds - cfg.target_duration)\n",
    "    \n",
    "        end_index = int(cfg.SR * (end_seconds + (cfg.train_duration - cfg.target_duration) / 2) ) + len(audio) // 3\n",
    "        start_index = int(cfg.SR * (start_seconds - (cfg.train_duration - cfg.target_duration) / 2) ) + len(audio) // 3\n",
    "        end_pad = int(cfg.SR * (cfg.train_duration - cfg.target_duration) / 2) \n",
    "        start_pad = int(cfg.SR * (cfg.train_duration - cfg.target_duration) / 2) \n",
    "        y = audio[start_index:end_index].astype(np.float32)\n",
    "        if i==0:\n",
    "            y[:start_pad] = 0\n",
    "        elif i==(len(seconds)-1):\n",
    "            y[-end_pad:] = 0\n",
    "        audios.append(y)\n",
    "\n",
    "    return audios\n",
    "\n",
    "def sigmoid(x):\n",
    "    s = 1 / (1 + np.exp(-x))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "104a3c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.684882Z",
     "iopub.status.busy": "2025-06-04T13:56:39.684588Z",
     "iopub.status.idle": "2025-06-04T13:56:39.696640Z",
     "shell.execute_reply": "2025-06-04T13:56:39.695577Z"
    },
    "papermill": {
     "duration": 0.021099,
     "end_time": "2025-06-04T13:56:39.698241",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.677142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_model_files(cfg):\n",
    "    \"\"\"\n",
    "    Find all .pth model files in the specified model directory\n",
    "    \"\"\"\n",
    "    model_files = []\n",
    "    \n",
    "    model_dir = Path(cfg.model_path)\n",
    "    \n",
    "    for path in model_dir.glob('**/*.pth'):\n",
    "        model_files.append(str(path))\n",
    "    \n",
    "    return model_files\n",
    "\n",
    "def load_models(cfg, num_classes):\n",
    "    \"\"\"\n",
    "    Load all found model files and prepare them for ensemble\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    \n",
    "    # model_files = find_model_files(cfg)\n",
    "    model_files = cfg.model_files\n",
    "    \n",
    "    if not model_files:\n",
    "        print(f\"Warning: No model files found under {cfg.model_path}!\")\n",
    "        return models\n",
    "    \n",
    "    print(f\"Found a total of {len(model_files)} model files.\")\n",
    "    \n",
    "    for i, model_path in enumerate(model_files):\n",
    "        try:\n",
    "            print(f\"Loading model: {model_path}\")\n",
    "            checkpoint = torch.load(model_path, map_location=torch.device(cfg.device), weights_only=False)\n",
    "            cfg_temp = checkpoint['cfg']\n",
    "            cfg_temp['device'] = cfg.device\n",
    "            \n",
    "            model = BirdCLEFModel(cfg_temp)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            model = model.to(cfg.device)\n",
    "            model.eval()\n",
    "            model.zero_grad()\n",
    "            model.half().float()\n",
    "            \n",
    "            models.append(model)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {model_path}: {e}\")\n",
    "    \n",
    "    return models\n",
    "\n",
    "def predict_on_spectrogram(audio_path, models, cfg, species_ids):\n",
    "    \"\"\"Process a single audio file and predict species presence for each 5-second segment\"\"\"\n",
    "    audio_path = str(audio_path)\n",
    "    predictions = []\n",
    "    row_ids = []\n",
    "    soundscape_id = Path(audio_path).stem\n",
    "\n",
    "    print(f\"Processing {soundscape_id}\")\n",
    "    audio_data = load_sample(audio_path, cfg)\n",
    "    for segment_idx, audio_input in enumerate(audio_data):\n",
    "        \n",
    "        end_time_sec = (segment_idx + 1) * cfg.target_duration\n",
    "        row_id = f\"{soundscape_id}_{end_time_sec}\"\n",
    "        row_ids.append(row_id)\n",
    "        \n",
    "        mel_spec = torch.tensor(audio_input, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        mel_spec = mel_spec.to(cfg.device)\n",
    "        \n",
    "        if len(models) == 1:\n",
    "            with torch.no_grad():\n",
    "                outputs = models[0].infer(mel_spec)\n",
    "                final_preds = outputs.squeeze()\n",
    "                # final_preds = torch.sigmoid(outputs).cpu().numpy().squeeze()\n",
    "\n",
    "        else:\n",
    "            segment_preds = []\n",
    "            for model in models:\n",
    "                with torch.no_grad():\n",
    "                    outputs = model.infer(mel_spec)\n",
    "                    probs = outputs.squeeze()\n",
    "                    # probs = torch.sigmoid(outputs).cpu().numpy().squeeze()\n",
    "                    segment_preds.append(probs)\n",
    "\n",
    "            \n",
    "            final_preds = np.mean(segment_preds, axis=0)\n",
    "                \n",
    "        predictions.append(final_preds)\n",
    "\n",
    "    predictions = np.stack(predictions,axis=0)\n",
    "    \n",
    "    return row_ids, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1776992c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.712834Z",
     "iopub.status.busy": "2025-06-04T13:56:39.712512Z",
     "iopub.status.idle": "2025-06-04T13:56:39.725762Z",
     "shell.execute_reply": "2025-06-04T13:56:39.724880Z"
    },
    "papermill": {
     "duration": 0.022395,
     "end_time": "2025-06-04T13:56:39.727353",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.704958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_inference(cfg, models, species_ids):\n",
    "    \"\"\"Run inference on all test soundscapes\"\"\"\n",
    "    test_files = list(Path(cfg.test_soundscapes).glob('*.ogg'))\n",
    "    if len(test_files) == 0:\n",
    "        test_files = sorted(glob(str(Path('/kaggle/input/birdclef-2025/train_soundscapes') / '*.ogg')))[:10]\n",
    "    \n",
    "    print(f\"Found {len(test_files)} test soundscapes\")\n",
    "\n",
    "    all_row_ids = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        results = list(\n",
    "        executor.map(\n",
    "            predict_on_spectrogram,\n",
    "            test_files,\n",
    "            itertools.repeat(models),\n",
    "            itertools.repeat(cfg),\n",
    "            itertools.repeat(species_ids)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for rids, preds in results:\n",
    "        all_row_ids.extend(rids)\n",
    "        all_predictions.extend(preds)\n",
    "    \n",
    "    return all_row_ids, all_predictions\n",
    "\n",
    "def create_submission(row_ids, predictions, species_ids, cfg):\n",
    "    \"\"\"Create submission dataframe\"\"\"\n",
    "    print(\"Creating submission dataframe...\")\n",
    "\n",
    "    submission_dict = {'row_id': row_ids}\n",
    "    \n",
    "    for i, species in enumerate(species_ids):\n",
    "        submission_dict[species] = [pred[i] for pred in predictions]\n",
    "\n",
    "    submission_df = pd.DataFrame(submission_dict)\n",
    "\n",
    "    submission_df.set_index('row_id', inplace=True)\n",
    "\n",
    "    sample_sub = pd.read_csv(cfg.submission_csv, index_col='row_id')\n",
    "\n",
    "    missing_cols = set(sample_sub.columns) - set(submission_df.columns)\n",
    "    if missing_cols:\n",
    "        print(f\"Warning: Missing {len(missing_cols)} species columns in submission\")\n",
    "        for col in missing_cols:\n",
    "            submission_df[col] = 0.0\n",
    "\n",
    "    submission_df = submission_df[sample_sub.columns]\n",
    "\n",
    "    submission_df = submission_df.reset_index()\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "\n",
    "def smooth_submission(submission_path):\n",
    "        \"\"\"\n",
    "        Post-process the submission CSV by smoothing predictions to enforce temporal consistency.\n",
    "        \n",
    "        For each soundscape (grouped by the file name part of 'row_id'), each row's predictions\n",
    "        are averaged with those of its neighbors using defined weights.\n",
    "        \n",
    "        :param submission_path: Path to the submission CSV file.\n",
    "        \"\"\"\n",
    "        print(\"Smoothing submission predictions...\")\n",
    "        sub = pd.read_csv(submission_path)\n",
    "        cols = sub.columns[1:]\n",
    "        groups = sub['row_id'].str.rsplit('_', n=1).str[0].values\n",
    "        unique_groups = np.unique(groups)\n",
    "        for group in unique_groups:\n",
    "            idx = np.where(groups == group)[0]\n",
    "            sub_group = sub.iloc[idx].copy()\n",
    "            predictions = sub_group[cols].values\n",
    "            new_predictions = predictions.copy()\n",
    "            if predictions.shape[0] > 2:\n",
    "                new_predictions[0] = (predictions[0]*0.6 + predictions[1]*0.3 + predictions[2]*0.1)\n",
    "                new_predictions[1] = (predictions[0]*0.2 + predictions[1]*0.6 + predictions[2]*0.2)\n",
    "                for i in range(2, predictions.shape[0]-2):\n",
    "                    new_predictions[i] = (predictions[i-2]*0.1 + predictions[i-1]*0.2 + predictions[i]*0.4 + predictions[i+1]*0.2 + predictions[i+2]*0.1)\n",
    "                new_predictions[-2] = (predictions[-3]*0.2 + predictions[-2]*0.6 + predictions[-1]*0.2)\n",
    "                new_predictions[-1] = (predictions[-3]*0.1 + predictions[-2]*0.3 + predictions[-1]*0.6)\n",
    "            sub.iloc[idx, 1:] = new_predictions\n",
    "        sub.to_csv(submission_path, index=False)\n",
    "        print(f\"Smoothed submission saved to {submission_path}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78d60615",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.742128Z",
     "iopub.status.busy": "2025-06-04T13:56:39.741133Z",
     "iopub.status.idle": "2025-06-04T13:56:39.747558Z",
     "shell.execute_reply": "2025-06-04T13:56:39.746630Z"
    },
    "papermill": {
     "duration": 0.015216,
     "end_time": "2025-06-04T13:56:39.749050",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.733834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():  # 定义主函数\n",
    "    start_time = time.time()  # 记录开始时间\n",
    "    print(\"Starting BirdCLEF-2025 inference...\")  # 打印开始推理的信息\n",
    "\n",
    "    models = load_models(cfg, num_classes)  # 加载模型\n",
    "    \n",
    "    if not models:  # 如果没有找到模型\n",
    "        print(\"No models found! Please check model paths.\")  # 打印错误信息\n",
    "        return  # 提前返回\n",
    "    \n",
    "    print(f\"Model usage: {'Single model' if len(models) == 1 else f'Ensemble of {len(models)} models'}\")  # 打印模型使用情况\n",
    "\n",
    "    row_ids, predictions = run_inference(cfg, models, species_ids)  # 运行推理获取结果\n",
    "\n",
    "    submission_df = create_submission(row_ids, predictions, species_ids, cfg)  # 创建提交数据框\n",
    "\n",
    "    submission_path = 'submission.csv'  # 设置提交文件路径\n",
    "    submission_df.to_csv(submission_path, index=False)  # 保存提交文件\n",
    "    print(f\"Submission saved to {submission_path}\")  # 打印保存信息\n",
    "\n",
    "    smooth_submission(submission_path)  # 对提交结果进行平滑处理\n",
    "    \n",
    "    end_time = time.time()  # 记录结束时间\n",
    "    print(f\"Inference completed in {(end_time - start_time)/60:.2f} minutes\")  # 打印完成时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af2a842d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.762994Z",
     "iopub.status.busy": "2025-06-04T13:56:39.762685Z",
     "iopub.status.idle": "2025-06-04T13:57:15.350718Z",
     "shell.execute_reply": "2025-06-04T13:57:15.349783Z"
    },
    "papermill": {
     "duration": 35.596804,
     "end_time": "2025-06-04T13:57:15.352214",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.755410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting BirdCLEF-2025 inference...\n",
      "Found a total of 1 model files.\n",
      "Loading model: /kaggle/input/bird2025-sed-ckpt/sedmodel.pth\n",
      "Model usage: Single model\n",
      "Found 10 test soundscapes\n",
      "Processing H02_20230420_074000\n",
      "Processing H02_20230420_112000\n",
      "Processing H02_20230420_154500\n",
      "Processing H02_20230420_164000\n",
      "Processing H02_20230420_223500\n",
      "Processing H02_20230421_093000\n",
      "Processing H02_20230421_113500\n",
      "Processing H02_20230421_170000\n",
      "Processing H02_20230421_190500\n",
      "Processing H02_20230421_233500\n",
      "Creating submission dataframe...\n",
      "Submission saved to submission.csv\n",
      "Smoothing submission predictions...\n",
      "Smoothed submission saved to submission.csv\n",
      "Inference completed in 0.59 minutes\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":  # 如果作为主程序运行\n",
    "    main()  # 执行主函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec755df",
   "metadata": {
    "papermill": {
     "duration": 0.007111,
     "end_time": "2025-06-04T13:57:15.366210",
     "exception": false,
     "start_time": "2025-06-04T13:57:15.359099",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"color: #6cb4e4;  text-align: center;  padding: 0.25em;  border-top: solid 2.5px #6cb4e4;  border-bottom: solid 2.5px #6cb4e4;  background: -webkit-repeating-linear-gradient(-45deg, #f0f8ff, #f0f8ff 3px,#e9f4ff 3px, #e9f4ff 7px);  background: repeating-linear-gradient(-45deg, #f0f8ff, #f0f8ff 3px,#e9f4ff 3px, #e9f4ff 7px);height:45px;\">\n",
    "<b>\n",
    "《《《最终融合》》》\n",
    "</b></h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72b2b97f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:57:15.381397Z",
     "iopub.status.busy": "2025-06-04T13:57:15.381008Z",
     "iopub.status.idle": "2025-06-04T13:57:15.385596Z",
     "shell.execute_reply": "2025-06-04T13:57:15.384510Z"
    },
    "papermill": {
     "duration": 0.014155,
     "end_time": "2025-06-04T13:57:15.387352",
     "exception": false,
     "start_time": "2025-06-04T13:57:15.373197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------- #\n",
    "# [重要]\n",
    "# * 融合权重\n",
    "# ------------------------------------------- #\n",
    "# 权重设置 sub_w=[0.75, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b69a4201",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:57:15.402884Z",
     "iopub.status.busy": "2025-06-04T13:57:15.402479Z",
     "iopub.status.idle": "2025-06-04T13:57:15.407564Z",
     "shell.execute_reply": "2025-06-04T13:57:15.406548Z"
    },
    "papermill": {
     "duration": 0.014954,
     "end_time": "2025-06-04T13:57:15.409480",
     "exception": false,
     "start_time": "2025-06-04T13:57:15.394526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list_TARGETs = sorted(os.listdir('/kaggle/input/birdclef-2025/train_audio/'))\n",
    "# list_targets_0 = [f'{TARGET} 0' for TARGET in list_TARGETs]\n",
    "# list_targets_1 = [f'{TARGET} 1' for TARGET in list_TARGETs]\n",
    "\n",
    "# df0 = pd.read_csv(\"/kaggle/working/submission.csv\")\n",
    "# df1 = pd.read_csv(\"/kaggle/working/submission1.csv\")\n",
    "\n",
    "# df0 = df0.rename(columns={TARGET : f'{TARGET} 0' for TARGET in list_TARGETs})\n",
    "# df1 = df1.rename(columns={TARGET : f'{TARGET} 1' for TARGET in list_TARGETs})\n",
    "\n",
    "# dfs = pd.merge(df0,df1,on=['row_id'])\n",
    "\n",
    "# for i in range(len(list_TARGETs)):\n",
    "#     dfs[list_TARGETs[i]] = dfs[list_targets_0[i]]*sub_w[0] + sub_w[1]*dfs[list_targets_1[i]]\n",
    "             \n",
    "# for col0,col1 in zip(list_targets_0, list_targets_1):\n",
    "#     del dfs[col0]\n",
    "#     del dfs[col1]\n",
    "    \n",
    "    \n",
    "# dfs.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60de7790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:57:15.425757Z",
     "iopub.status.busy": "2025-06-04T13:57:15.425391Z",
     "iopub.status.idle": "2025-06-04T13:57:16.590291Z",
     "shell.execute_reply": "2025-06-04T13:57:16.589162Z"
    },
    "papermill": {
     "duration": 1.175154,
     "end_time": "2025-06-04T13:57:16.592085",
     "exception": false,
     "start_time": "2025-06-04T13:57:15.416931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.special import logit, expit  # 导入特殊函数logit和expit（逆logit）\n",
    "\n",
    "list_TARGETs = sorted(os.listdir('/kaggle/input/birdclef-2025/train_audio/'))  # 获取并排序所有鸟类标签\n",
    "\n",
    "df0 = pd.read_csv(\"/kaggle/working/submission.csv\")  # 读取第一个模型的预测结果\n",
    "df1 = pd.read_csv(\"/kaggle/working/submission1.csv\")  # 读取第二个模型的预测结果\n",
    "\n",
    "# 保证列名一致\n",
    "for TARGET in list_TARGETs:  # 遍历所有鸟类标签\n",
    "    if f'{TARGET} 0' in df0.columns:  # 如果列名带有后缀\n",
    "        df0[TARGET] = df0[f'{TARGET} 0']  # 规范化列名\n",
    "    if f'{TARGET} 1' in df1.columns:  # 如果列名带有后缀\n",
    "        df1[TARGET] = df1[f'{TARGET} 1']  # 规范化列名\n",
    "\n",
    "cols = [col for col in df0.columns if col != 'row_id']  # 获取除行ID外的所有列名\n",
    "\n",
    "blend = df0[['row_id']].copy()  # 创建仅含行ID的新数据框\n",
    "for col in cols:  # 遍历所有鸟类列\n",
    "    # 在对数空间中加权融合，防止极端概率导致logit溢出\n",
    "    blend[col] = expit(0.75*logit(df0[col].clip(1e-6, 1-1e-6)) + 0.25*logit(df1[col].clip(1e-6, 1-1e-6)))\n",
    "blend.to_csv(\"submission.csv\", index=False)  # 保存融合后的结果文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9894d4cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:57:16.607753Z",
     "iopub.status.busy": "2025-06-04T13:57:16.607438Z",
     "iopub.status.idle": "2025-06-04T13:57:16.960819Z",
     "shell.execute_reply": "2025-06-04T13:57:16.959633Z"
    },
    "papermill": {
     "duration": 0.362976,
     "end_time": "2025-06-04T13:57:16.962565",
     "exception": false,
     "start_time": "2025-06-04T13:57:16.599589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np  # 导入数值计算库\n",
    "import pandas as pd  # 导入数据处理库\n",
    "\n",
    "# 鸟类共现调整\n",
    "num_classes = len(list_TARGETs)  # 获取鸟类类别数量\n",
    "co_matrix = np.eye(num_classes)  # 创建单位矩阵作为共现矩阵（可以用实际统计的共现数据替换）\n",
    "\n",
    "def co_occurrence_boost(sub_path, co_matrix, threshold=0.7):  # 定义基于共现的预测增强函数\n",
    "    sub = pd.read_csv(sub_path)  # 读取提交文件\n",
    "    cols = [col for col in sub.columns if col != 'row_id']  # 获取所有鸟类列名\n",
    "    preds = sub[cols].values  # 提取预测值数组\n",
    "    boosted = preds.copy()  # 创建预测值的副本\n",
    "    for i in range(preds.shape[1]):  # 遍历每个鸟类类别\n",
    "        high_idx = preds[:, i] > threshold  # 找出高置信度预测\n",
    "        for j in range(preds.shape[1]):  # 遍历每个鸟类类别\n",
    "            if i != j:  # 如果不是同一个类别\n",
    "                boosted[high_idx, j] += preds[high_idx, i] * co_matrix[i, j]  # 基于共现矩阵增强预测\n",
    "    boosted = np.clip(boosted, 0, 1)  # 将值限制在0到1之间\n",
    "    sub[cols] = boosted  # 更新数据框中的预测值\n",
    "    sub.to_csv(sub_path, index=False)  # 保存更新后的预测结果\n",
    "\n",
    "co_occurrence_boost(\"submission.csv\", co_matrix, threshold=0.7)  # 应用共现增强到最终结果"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "sourceId": 91844,
     "sourceType": "competition"
    },
    {
     "datasetId": 7430593,
     "sourceId": 11828260,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7459867,
     "sourceId": 11870659,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 98.342347,
   "end_time": "2025-06-04T13:57:20.259024",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-04T13:55:41.916677",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
