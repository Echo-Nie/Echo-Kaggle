{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4109f3d",
   "metadata": {
    "papermill": {
     "duration": 0.007251,
     "end_time": "2025-06-04T13:55:47.103166",
     "exception": false,
     "start_time": "2025-06-04T13:55:47.095915",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"color: #6cb4e4;  text-align: center;  padding: 0.25em;  border-top: solid 2.5px #6cb4e4;  border-bottom: solid 2.5px #6cb4e4;  background: -webkit-repeating-linear-gradient(-45deg, #f0f8ff, #f0f8ff 3px,#e9f4ff 3px, #e9f4ff 7px);  background: repeating-linear-gradient(-45deg, #f0f8ff, #f0f8ff 3px,#e9f4ff 3px, #e9f4ff 7px);height:45px;\">\n",
    "<b>\n",
    "ã€Šã€Šã€ŠSubmission1(nfnet)ã€‹ã€‹ã€‹\n",
    "</b></h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c1ca3ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:55:47.117877Z",
     "iopub.status.busy": "2025-06-04T13:55:47.117076Z",
     "iopub.status.idle": "2025-06-04T13:56:08.450980Z",
     "shell.execute_reply": "2025-06-04T13:56:08.450015Z"
    },
    "papermill": {
     "duration": 21.342855,
     "end_time": "2025-06-04T13:56:08.452776",
     "exception": false,
     "start_time": "2025-06-04T13:55:47.109921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np  # å¯¼å…¥æ•°å€¼è®¡ç®—åº“\n",
    "import torchaudio.transforms as AT  # å¯¼å…¥éŸ³é¢‘è½¬æ¢æ¨¡å—\n",
    "import concurrent.futures  # å¯¼å…¥å¹¶è¡Œå¤„ç†æ¨¡å—\n",
    "import os  # å¯¼å…¥æ“ä½œç³»ç»Ÿæ¥å£æ¨¡å—\n",
    "import gc  # å¯¼å…¥åƒåœ¾æ”¶é›†æ¨¡å—\n",
    "import warnings  # å¯¼å…¥è­¦å‘Šæ§åˆ¶æ¨¡å—\n",
    "import logging  # å¯¼å…¥æ—¥å¿—æ¨¡å—\n",
    "import time  # å¯¼å…¥æ—¶é—´ç›¸å…³æ¨¡å—\n",
    "import pandas as pd  # å¯¼å…¥æ•°æ®å¤„ç†åº“\n",
    "import soundfile as sf  # å¯¼å…¥éŸ³é¢‘æ–‡ä»¶è¯»å†™æ¨¡å—\n",
    "import torch  # å¯¼å…¥PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶\n",
    "import torch.nn as nn  # å¯¼å…¥ç¥ç»ç½‘ç»œæ¨¡å—\n",
    "import torch.nn.functional as F  # å¯¼å…¥å‡½æ•°å¼æ¥å£\n",
    "import timm  # å¯¼å…¥é¢„è®­ç»ƒæ¨¡å‹åº“\n",
    "from glob import glob  # å¯¼å…¥æ–‡ä»¶è·¯å¾„åŒ¹é…æ¨¡å—\n",
    "import torchaudio  # å¯¼å…¥éŸ³é¢‘å¤„ç†åº“\n",
    "import random  # å¯¼å…¥éšæœºæ•°æ¨¡å—\n",
    "import itertools  # å¯¼å…¥è¿­ä»£å™¨å·¥å…·\n",
    "import concurrent.futures  # å¯¼å…¥å¹¶è¡Œå¤„ç†æ¨¡å—\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # å¿½ç•¥è­¦å‘Šä¿¡æ¯\n",
    "logging.basicConfig(level=logging.ERROR)  # è®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55394b5e",
   "metadata": {
    "papermill": {
     "duration": 0.005624,
     "end_time": "2025-06-04T13:56:08.464641",
     "exception": false,
     "start_time": "2025-06-04T13:56:08.459017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ğŸ¦ BirdCLEF 2025: åŠ æƒæ··åˆæ¨ç† (LB 0.878)\n",
    "\n",
    "## ğŸ§  æ¦‚è¿°\n",
    "\n",
    "æœ¬notebookä½¿ç”¨**åŠ æƒæ··åˆ**æ–¹æ³•åœ¨å…¬å…±æ’è¡Œæ¦œä¸Šè·å¾—äº†**0.878**çš„åˆ†æ•°ã€‚\n",
    "\n",
    "## ğŸ§© ä½¿ç”¨çš„æ¨¡å‹\n",
    "\n",
    "æœ€ç»ˆé¢„æµ‹åŸºäºä»¥ä¸‹å…¬å…±æ¨¡å‹çš„é›†æˆï¼š\n",
    "\n",
    "- ğŸ“˜ **[Bird2025 | å•ä¸€SEDæ¨¡å‹æ¨ç† [LB 0.857]](https://www.kaggle.com/code/i2nfinit3y/bird2025-single-sed-model-inference-lb-0-857)**  \n",
    "  ä½œè€…ï¼š[I2nfinit3y](https://www.kaggle.com/i2nfinit3y)  \n",
    "  ä¸€ä¸ªå¼ºå¤§çš„å•ä¸€SEDæ¨¡å‹ï¼Œä½œä¸ºé›†æˆç»„ä»¶ä¹‹ä¸€çš„åŸºç¡€ã€‚\n",
    "\n",
    "- ğŸ§ª **[ä½æ’åé¢„æµ‹çš„å¹‚è°ƒæ•´åå¤„ç†](https://www.kaggle.com/code/myso1987/post-processing-with-power-adjustment-for-low-rank)**  \n",
    "  ä½œè€…ï¼š[MYSO](https://www.kaggle.com/myso1987)  \n",
    "  è¯¥notebookå¼•å…¥äº†ä¸€ç§å·§å¦™çš„åå¤„ç†æŠ€æœ¯ï¼Œé€šè¿‡å¹‚å˜æ¢æå‡ä½ç½®ä¿¡åº¦é¢„æµ‹ã€‚\n",
    "\n",
    "- ğŸ”— **[Bird25 | åŠ æƒæ··åˆ | nfnet + convnextv2 | LB.860](https://www.kaggle.com/code/hideyukizushi/bird25-weightedblend-nfnet-convnextv2-lb-860)**  \n",
    "  ä½œè€…ï¼š[yukiZ](https://www.kaggle.com/hideyukizushi)  \n",
    "  æä¾›äº†ç”¨äºç»„åˆæ¨¡å‹è¾“å‡ºçš„æ ¸å¿ƒæ··åˆé€»è¾‘ã€‚\n",
    "\n",
    "## âš–ï¸ åŠ æƒæ··åˆç­–ç•¥\n",
    "\n",
    "æˆ‘ä»¬ä½¿ç”¨ä¸¤ä¸ªæ¨¡å‹è¾“å‡ºçš„åŠ æƒå¹³å‡å€¼ï¼Œå…·ä½“å¦‚ä¸‹ï¼š\n",
    "\n",
    "- **nfnet**: 25%\n",
    "- **seresnext**: 75%\n",
    "\n",
    "è™½ç„¶è¿™ç§æ··åˆæ–¹æ³•åœ¨æ’è¡Œæ¦œä¸Šè·å¾—äº†é«˜åˆ†ï¼Œä½†å®ƒå¯èƒ½è¿‡æ‹Ÿåˆåˆ°å…¬å…±æµ‹è¯•é›† â€” è¿™æ˜¯2022å¹´è‡³2024å¹´BirdCLEFç«èµ›ä¸­å¸¸è§çš„æ¨¡å¼ã€‚è¯„ä¼°ç»“æœæ—¶è¯·è€ƒè™‘è¿™ä¸€ç‚¹ã€‚\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce9bbdb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:08.478054Z",
     "iopub.status.busy": "2025-06-04T13:56:08.477527Z",
     "iopub.status.idle": "2025-06-04T13:56:08.570418Z",
     "shell.execute_reply": "2025-06-04T13:56:08.569220Z"
    },
    "papermill": {
     "duration": 0.101676,
     "end_time": "2025-06-04T13:56:08.572140",
     "exception": false,
     "start_time": "2025-06-04T13:56:08.470464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug mode: True\n",
      "Number of test soundscapes: 8\n"
     ]
    }
   ],
   "source": [
    "test_audio_dir = '../input/birdclef-2025/test_soundscapes/'  # è®¾ç½®æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ç›®å½•è·¯å¾„\n",
    "file_list = [f for f in sorted(os.listdir(test_audio_dir))]  # è·å–ç›®å½•ä¸­æ‰€æœ‰æ–‡ä»¶çš„æ’åºåˆ—è¡¨\n",
    "file_list = [file.split('.')[0] for file in file_list if file.endswith('.ogg')]  # æå–æ‰€æœ‰.oggæ–‡ä»¶çš„æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰\n",
    "\n",
    "debug = False  # åˆå§‹åŒ–è°ƒè¯•æ¨¡å¼ä¸ºå…³é—­\n",
    "if len(file_list) == 0:  # å¦‚æœæµ‹è¯•ç›®å½•ä¸ºç©º\n",
    "    debug = True  # å¼€å¯è°ƒè¯•æ¨¡å¼\n",
    "    debug_st_num = 5  # è®¾ç½®è°ƒè¯•èµ·å§‹æ ·æœ¬ç¼–å·\n",
    "    debug_num = 8  # è®¾ç½®è°ƒè¯•æ ·æœ¬æ•°é‡\n",
    "    test_audio_dir = '../input/birdclef-2025/train_soundscapes/'  # æ”¹ç”¨è®­ç»ƒé›†éŸ³é¢‘æ–‡ä»¶ä½œä¸ºæµ‹è¯•\n",
    "    file_list = [f for f in sorted(os.listdir(test_audio_dir))]  # è·å–è®­ç»ƒé›†ç›®å½•ä¸­æ‰€æœ‰æ–‡ä»¶\n",
    "    file_list = [file.split('.')[0] for file in file_list if file.endswith('.ogg')]  # æå–æ‰€æœ‰.oggæ–‡ä»¶çš„æ–‡ä»¶å\n",
    "    file_list = file_list[debug_st_num:debug_st_num+debug_num]  # é€‰å–æŒ‡å®šèŒƒå›´çš„æ–‡ä»¶è¿›è¡Œè°ƒè¯•\n",
    "\n",
    "print('Debug mode:', debug)  # æ‰“å°å½“å‰è°ƒè¯•æ¨¡å¼çŠ¶æ€\n",
    "print('Number of test soundscapes:', len(file_list))  # æ‰“å°æµ‹è¯•éŸ³é¢‘æ–‡ä»¶æ•°é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a9e535d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:08.586005Z",
     "iopub.status.busy": "2025-06-04T13:56:08.585664Z",
     "iopub.status.idle": "2025-06-04T13:56:08.592061Z",
     "shell.execute_reply": "2025-06-04T13:56:08.591059Z"
    },
    "papermill": {
     "duration": 0.01535,
     "end_time": "2025-06-04T13:56:08.593840",
     "exception": false,
     "start_time": "2025-06-04T13:56:08.578490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adaptive_power(p, top_k=30, min_exp=1.5, max_exp=3.0, inplace=True):\n",
    "    if not inplace:  # å¦‚æœä¸è¿›è¡ŒåŸåœ°æ“ä½œ\n",
    "        p = p.copy()  # åˆ›å»ºè¾“å…¥æ•°ç»„çš„å‰¯æœ¬\n",
    "    col_max = p.max(axis=0)  # è®¡ç®—æ¯åˆ—çš„æœ€å¤§å€¼\n",
    "    ranks = np.argsort(-col_max)  # æ ¹æ®åˆ—æœ€å¤§å€¼é™åºæ’åºè·å–ç´¢å¼•\n",
    "    exps = np.linspace(max_exp, min_exp, len(col_max))  # åˆ›å»ºçº¿æ€§é€’å‡çš„æŒ‡æ•°å€¼æ•°ç»„\n",
    "    for i, col in enumerate(ranks[top_k:]):  # éå†æ’ååœ¨top_kä¹‹åçš„åˆ—\n",
    "        p[:, col] = p[:, col] ** exps[i]  # å¯¹æ¯åˆ—åº”ç”¨ä¸åŒçš„å¹‚æ¬¡å˜æ¢\n",
    "    return p  # è¿”å›å¤„ç†åçš„æ•°ç»„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "430d2e3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:08.607783Z",
     "iopub.status.busy": "2025-06-04T13:56:08.607432Z",
     "iopub.status.idle": "2025-06-04T13:56:08.666204Z",
     "shell.execute_reply": "2025-06-04T13:56:08.664921Z"
    },
    "papermill": {
     "duration": 0.067886,
     "end_time": "2025-06-04T13:56:08.668118",
     "exception": false,
     "start_time": "2025-06-04T13:56:08.600232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "wav_sec = 5  # è®¾ç½®æ¯ä¸ªéŸ³é¢‘ç‰‡æ®µçš„æ—¶é•¿ä¸º5ç§’\n",
    "sample_rate = 32000  # è®¾ç½®é‡‡æ ·ç‡ä¸º32kHz\n",
    "min_segment = sample_rate*wav_sec  # è®¡ç®—æœ€å°éŸ³é¢‘ç‰‡æ®µçš„æ ·æœ¬æ•°\n",
    "\n",
    "class_labels = sorted(os.listdir('../input/birdclef-2025/train_audio/'))  # è·å–å¹¶æ’åºæ‰€æœ‰é¸Ÿç±»æ ‡ç­¾\n",
    "\n",
    "n_fft=1024  # è®¾ç½®å¿«é€Ÿå‚…é‡Œå¶å˜æ¢çš„çª—å£å¤§å°\n",
    "win_length=1024  # è®¾ç½®çª—å£é•¿åº¦\n",
    "hop_length=512  # è®¾ç½®çª—å£ç§»åŠ¨æ­¥é•¿\n",
    "f_min=40  # è®¾ç½®æœ€å°é¢‘ç‡\n",
    "f_max=16000  # è®¾ç½®æœ€å¤§é¢‘ç‡\n",
    "n_mels=128  # è®¾ç½®æ¢…å°”é¢‘è°±çš„é¢‘æ®µæ•°\n",
    "\n",
    "mel_spectrogram = AT.MelSpectrogram(  # åˆ›å»ºæ¢…å°”é¢‘è°±è½¬æ¢å™¨\n",
    "    sample_rate=sample_rate,  # æŒ‡å®šé‡‡æ ·ç‡\n",
    "    n_fft=n_fft,  # æŒ‡å®šFFTçª—å£å¤§å°\n",
    "    win_length=win_length,  # æŒ‡å®šçª—å£é•¿åº¦\n",
    "    hop_length=hop_length,  # æŒ‡å®šçª—å£ç§»åŠ¨æ­¥é•¿\n",
    "    center=True,  # å¯ç”¨ä¸­å¿ƒå¡«å……\n",
    "    f_min=f_min,  # æŒ‡å®šæœ€å°é¢‘ç‡\n",
    "    f_max=f_max,  # æŒ‡å®šæœ€å¤§é¢‘ç‡\n",
    "    pad_mode=\"reflect\",  # ä½¿ç”¨åå°„å¡«å……æ¨¡å¼\n",
    "    power=2.0,  # ä½¿ç”¨åŠŸç‡è°±\n",
    "    norm='slaney',  # ä½¿ç”¨Slaneyå½’ä¸€åŒ–\n",
    "    n_mels=n_mels,  # æŒ‡å®šæ¢…å°”é¢‘æ®µæ•°\n",
    "    mel_scale=\"htk\",  # ä½¿ç”¨HTKæ¢…å°”å°ºåº¦\n",
    ")\n",
    "\n",
    "def normalize_std(spec, eps=1e-6):  # å®šä¹‰æ ‡å‡†åŒ–å‡½æ•°\n",
    "    mean = torch.mean(spec)  # è®¡ç®—å‡å€¼\n",
    "    std = torch.std(spec)  # è®¡ç®—æ ‡å‡†å·®\n",
    "    return torch.where(std == 0, spec-mean, (spec - mean) / (std+eps))  # æ ‡å‡†åŒ–ï¼Œå¹¶å¤„ç†æ ‡å‡†å·®ä¸º0çš„æƒ…å†µ\n",
    "\n",
    "def audio_to_mel(filepath=None):  # å®šä¹‰éŸ³é¢‘è½¬æ¢…å°”é¢‘è°±çš„å‡½æ•°\n",
    "    waveform, sample_rate = torchaudio.load(filepath,backend=\"soundfile\")  # åŠ è½½éŸ³é¢‘æ–‡ä»¶\n",
    "    len_wav = waveform.shape[1]  # è·å–éŸ³é¢‘é•¿åº¦\n",
    "    waveform = waveform[0,:].reshape(1, len_wav)  # å°†ç«‹ä½“å£°è½¬ä¸ºå•å£°é“\n",
    "    PREDS = []  # åˆå§‹åŒ–é¢„æµ‹ç»“æœåˆ—è¡¨\n",
    "    for i in range(12):  # å¯¹æ¯ä¸ª5ç§’ç‰‡æ®µè¿›è¡Œå¤„ç†\n",
    "        waveform2 = waveform[:,i*sample_rate*5:i*sample_rate*5+sample_rate*5]  # æå–5ç§’ç‰‡æ®µ\n",
    "        melspec = mel_spectrogram(waveform2)  # è½¬æ¢ä¸ºæ¢…å°”é¢‘è°±\n",
    "        melspec = torch.log(melspec+1e-6)  # å¯¹é¢‘è°±å–å¯¹æ•°\n",
    "        melspec = normalize_std(melspec)  # æ ‡å‡†åŒ–é¢‘è°±\n",
    "        melspec = torch.unsqueeze(melspec, dim=0)  # å¢åŠ æ‰¹æ¬¡ç»´åº¦\n",
    "        \n",
    "        PREDS.append(melspec)  # æ·»åŠ åˆ°ç»“æœåˆ—è¡¨\n",
    "    return torch.vstack(PREDS)  # å‚ç›´å †å æ‰€æœ‰é¢‘è°±å¹¶è¿”å›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46c5c1b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:08.684183Z",
     "iopub.status.busy": "2025-06-04T13:56:08.683838Z",
     "iopub.status.idle": "2025-06-04T13:56:08.702303Z",
     "shell.execute_reply": "2025-06-04T13:56:08.701307Z"
    },
    "papermill": {
     "duration": 0.027919,
     "end_time": "2025-06-04T13:56:08.703973",
     "exception": false,
     "start_time": "2025-06-04T13:56:08.676054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_layer(layer):  # åˆå§‹åŒ–ç½‘ç»œå±‚å‡½æ•°\n",
    "    nn.init.xavier_uniform_(layer.weight)  # ä½¿ç”¨Xavierå‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–æƒé‡\n",
    "    if hasattr(layer, \"bias\"):  # å¦‚æœå±‚æœ‰åç½®å‚æ•°\n",
    "        if layer.bias is not None:  # å¦‚æœåç½®ä¸ä¸ºNone\n",
    "            layer.bias.data.fill_(0.)  # å°†åç½®åˆå§‹åŒ–ä¸º0\n",
    "\n",
    "\n",
    "def init_bn(bn):  # åˆå§‹åŒ–æ‰¹å½’ä¸€åŒ–å±‚å‡½æ•°\n",
    "    bn.bias.data.fill_(0.)  # æ‰¹å½’ä¸€åŒ–åç½®åˆå§‹åŒ–ä¸º0\n",
    "    bn.weight.data.fill_(1.0)  # æ‰¹å½’ä¸€åŒ–æƒé‡åˆå§‹åŒ–ä¸º1\n",
    "\n",
    "\n",
    "def init_weights(model):  # æ ¹æ®å±‚ç±»å‹åˆå§‹åŒ–æ¨¡å‹æƒé‡çš„å‡½æ•°\n",
    "    classname = model.__class__.__name__  # è·å–æ¨¡å‹ç±»å\n",
    "    if classname.find(\"Conv2d\") != -1:  # å¦‚æœæ˜¯å·ç§¯å±‚\n",
    "        nn.init.xavier_uniform_(model.weight, gain=np.sqrt(2))  # ä½¿ç”¨Xavieråˆå§‹åŒ–æƒé‡\n",
    "        model.bias.data.fill_(0)  # åç½®åˆå§‹åŒ–ä¸º0\n",
    "    elif classname.find(\"BatchNorm\") != -1:  # å¦‚æœæ˜¯æ‰¹å½’ä¸€åŒ–å±‚\n",
    "        model.weight.data.normal_(1.0, 0.02)  # æƒé‡åˆå§‹åŒ–ä¸ºå‡å€¼1.0ï¼Œæ ‡å‡†å·®0.02çš„æ­£æ€åˆ†å¸ƒ\n",
    "        model.bias.data.fill_(0)  # åç½®åˆå§‹åŒ–ä¸º0\n",
    "    elif classname.find(\"GRU\") != -1:  # å¦‚æœæ˜¯GRUå±‚\n",
    "        for weight in model.parameters():  # éå†æ‰€æœ‰å‚æ•°\n",
    "            if len(weight.size()) > 1:  # å¦‚æœå‚æ•°ç»´åº¦å¤§äº1\n",
    "                nn.init.orghogonal_(weight.data)  # ä½¿ç”¨æ­£äº¤åˆå§‹åŒ–\n",
    "    elif classname.find(\"Linear\") != -1:  # å¦‚æœæ˜¯çº¿æ€§å±‚\n",
    "        model.weight.data.normal_(0, 0.01)  # æƒé‡åˆå§‹åŒ–ä¸ºå‡å€¼0ï¼Œæ ‡å‡†å·®0.01çš„æ­£æ€åˆ†å¸ƒ\n",
    "        model.bias.data.zero_()  # åç½®åˆå§‹åŒ–ä¸º0\n",
    "\n",
    "\n",
    "def interpolate(x, ratio):  # æ—¶é—´ç»´åº¦æ’å€¼å‡½æ•°\n",
    "    (batch_size, time_steps, classes_num) = x.shape  # è·å–è¾“å…¥å½¢çŠ¶\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)  # åœ¨æ—¶é—´ç»´åº¦é‡å¤\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)  # é‡å¡‘å½¢çŠ¶\n",
    "    return upsampled  # è¿”å›ä¸Šé‡‡æ ·ç»“æœ\n",
    "\n",
    "\n",
    "def pad_framewise_output(framewise_output, frames_num):  # å¸§çº§è¾“å‡ºå¡«å……å‡½æ•°\n",
    "    output = F.interpolate(  # ä½¿ç”¨åŒçº¿æ€§æ’å€¼\n",
    "        framewise_output.unsqueeze(1),  # å¢åŠ ç»´åº¦\n",
    "        size=(frames_num, framewise_output.size(2)),  # è®¾ç½®ç›®æ ‡å¤§å°\n",
    "        align_corners=True,  # å¯¹é½è§’ç‚¹\n",
    "        mode=\"bilinear\").squeeze(1)  # ä½¿ç”¨åŒçº¿æ€§æ’å€¼å¹¶å‹ç¼©ç»´åº¦\n",
    "\n",
    "    return output  # è¿”å›å¡«å……åçš„è¾“å‡º\n",
    "\n",
    "\n",
    "class AttBlockV2(nn.Module):  # æ³¨æ„åŠ›å—V2å®šä¹‰\n",
    "    def __init__(self,\n",
    "                 in_features: int,  # è¾“å…¥ç‰¹å¾ç»´åº¦\n",
    "                 out_features: int,  # è¾“å‡ºç‰¹å¾ç»´åº¦\n",
    "                 activation=\"linear\"):  # æ¿€æ´»å‡½æ•°ç±»å‹\n",
    "        super().__init__()  # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–\n",
    "\n",
    "        self.activation = activation  # è®¾ç½®æ¿€æ´»å‡½æ•°\n",
    "        self.att = nn.Conv1d(  # æ³¨æ„åŠ›å·ç§¯å±‚\n",
    "            in_channels=in_features,  # è¾“å…¥é€šé“æ•°\n",
    "            out_channels=out_features,  # è¾“å‡ºé€šé“æ•°\n",
    "            kernel_size=1,  # å·ç§¯æ ¸å¤§å°\n",
    "            stride=1,  # æ­¥é•¿\n",
    "            padding=0,  # å¡«å……\n",
    "            bias=True)  # ä½¿ç”¨åç½®\n",
    "        self.cla = nn.Conv1d(  # åˆ†ç±»å·ç§¯å±‚\n",
    "            in_channels=in_features,  # è¾“å…¥é€šé“æ•°\n",
    "            out_channels=out_features,  # è¾“å‡ºé€šé“æ•°\n",
    "            kernel_size=1,  # å·ç§¯æ ¸å¤§å°\n",
    "            stride=1,  # æ­¥é•¿\n",
    "            padding=0,  # å¡«å……\n",
    "            bias=True)  # ä½¿ç”¨åç½®\n",
    "\n",
    "        self.init_weights()  # åˆå§‹åŒ–æƒé‡\n",
    "\n",
    "    def init_weights(self):  # åˆå§‹åŒ–æƒé‡æ–¹æ³•\n",
    "        init_layer(self.att)  # åˆå§‹åŒ–æ³¨æ„åŠ›å±‚\n",
    "        init_layer(self.cla)  # åˆå§‹åŒ–åˆ†ç±»å±‚\n",
    "\n",
    "    def forward(self, x):  # å‰å‘ä¼ æ’­\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)  # è®¡ç®—å½’ä¸€åŒ–æ³¨æ„åŠ›\n",
    "        cla = self.nonlinear_transform(self.cla(x))  # åº”ç”¨éçº¿æ€§å˜æ¢åˆ°åˆ†ç±»è¾“å‡º\n",
    "        x = torch.sum(norm_att * cla, dim=2)  # è®¡ç®—åŠ æƒå’Œ\n",
    "        return x, norm_att, cla  # è¿”å›è¾“å‡ºã€æ³¨æ„åŠ›æƒé‡å’Œåˆ†ç±»è¾“å‡º\n",
    "\n",
    "    def nonlinear_transform(self, x):  # éçº¿æ€§å˜æ¢å‡½æ•°\n",
    "        if self.activation == 'linear':  # å¦‚æœæ˜¯çº¿æ€§æ¿€æ´»\n",
    "            return x  # ç›´æ¥è¿”å›è¾“å…¥\n",
    "        elif self.activation == 'sigmoid':  # å¦‚æœæ˜¯sigmoidæ¿€æ´»\n",
    "            return torch.sigmoid(x)  # åº”ç”¨sigmoidå‡½æ•°\n",
    "\n",
    "\n",
    "class TimmSED(nn.Module):  # åŸºäºTimmçš„å£°éŸ³äº‹ä»¶æ£€æµ‹æ¨¡å‹\n",
    "    def __init__(self, base_model_name: str, pretrained=False, num_classes=24, in_channels=1, n_mels=24):  # åˆå§‹åŒ–å‡½æ•°\n",
    "        super().__init__()  # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(n_mels)  # åˆ›å»ºæ‰¹å½’ä¸€åŒ–å±‚\n",
    "\n",
    "        base_model = timm.create_model(  # åˆ›å»ºåŸºç¡€æ¨¡å‹\n",
    "            base_model_name, pretrained=pretrained, in_chans=in_channels)\n",
    "        layers = list(base_model.children())[:-2]  # æå–é™¤æœ€åä¸¤å±‚å¤–çš„æ‰€æœ‰å±‚\n",
    "        self.encoder = nn.Sequential(*layers)  # åˆ›å»ºç¼–ç å™¨\n",
    "\n",
    "        in_features = base_model.num_features  # è·å–ç‰¹å¾ç»´åº¦\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features, in_features, bias=True)  # åˆ›å»ºå…¨è¿æ¥å±‚\n",
    "        self.att_block2 = AttBlockV2(  # åˆ›å»ºæ³¨æ„åŠ›å—\n",
    "            in_features, num_classes, activation=\"sigmoid\")\n",
    "\n",
    "        self.init_weight()  # åˆå§‹åŒ–æƒé‡\n",
    "\n",
    "    def init_weight(self):  # åˆå§‹åŒ–æƒé‡æ–¹æ³•\n",
    "        init_bn(self.bn0)  # åˆå§‹åŒ–æ‰¹å½’ä¸€åŒ–å±‚\n",
    "        init_layer(self.fc1)  # åˆå§‹åŒ–å…¨è¿æ¥å±‚\n",
    "        \n",
    "\n",
    "    def forward(self, input_data):  # å‰å‘ä¼ æ’­\n",
    "        x = input_data.transpose(2,3)  # è½¬ç½®è¾“å…¥æ•°æ®ç»´åº¦\n",
    "        x = torch.cat((x,x,x),1)  # åœ¨é€šé“ç»´åº¦å¤åˆ¶ä¸‰æ¬¡\n",
    "\n",
    "        x = x.transpose(2, 3)  # å†æ¬¡è½¬ç½®ç»´åº¦\n",
    "\n",
    "        x = self.encoder(x)  # é€šè¿‡ç¼–ç å™¨\n",
    "        \n",
    "        x = torch.mean(x, dim=2)  # åœ¨é¢‘ç‡ç»´åº¦æ±‚å¹³å‡\n",
    "\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)  # æœ€å¤§æ± åŒ–\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)  # å¹³å‡æ± åŒ–\n",
    "        x = x1 + x2  # åˆå¹¶æ± åŒ–ç»“æœ\n",
    "\n",
    "        x = x.transpose(1, 2)  # è½¬ç½®ç»´åº¦\n",
    "        x = F.relu_(self.fc1(x))  # åº”ç”¨ReLUæ¿€æ´»å‡½æ•°\n",
    "        x = x.transpose(1, 2)  # å†æ¬¡è½¬ç½®ç»´åº¦\n",
    "\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block2(x)  # é€šè¿‡æ³¨æ„åŠ›å—\n",
    "        logit = torch.sum(norm_att * self.att_block2.cla(x), dim=2)  # è®¡ç®—logitè¾“å‡º\n",
    "\n",
    "        output_dict = {  # åˆ›å»ºè¾“å‡ºå­—å…¸\n",
    "            'logit': logit,  # ä¿å­˜logit\n",
    "        }\n",
    "\n",
    "        return output_dict  # è¿”å›è¾“å‡ºå­—å…¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee33c47d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:08.718248Z",
     "iopub.status.busy": "2025-06-04T13:56:08.717142Z",
     "iopub.status.idle": "2025-06-04T13:56:08.724989Z",
     "shell.execute_reply": "2025-06-04T13:56:08.723941Z"
    },
    "papermill": {
     "duration": 0.016327,
     "end_time": "2025-06-04T13:56:08.726425",
     "exception": false,
     "start_time": "2025-06-04T13:56:08.710098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/kaggle/input/birdclef-2025-sed-models-p/sed0.pth',\n",
       " '/kaggle/input/birdclef-2025-sed-models-p/sed1.pth',\n",
       " '/kaggle/input/birdclef-2025-sed-models-p/sed2.pth']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_name='eca_nfnet_l0'  # è®¾ç½®åŸºç¡€æ¨¡å‹åç§°ä¸ºECA-NFNet-L0\n",
    "pretrained=False  # ä¸ä½¿ç”¨é¢„è®­ç»ƒæƒé‡\n",
    "in_channels=3  # è®¾ç½®è¾“å…¥é€šé“æ•°ä¸º3\n",
    "\n",
    "MODELS = [f'/kaggle/input/birdclef-2025-sed-models-p/sed{i}.pth' for i in range(3)]  # åˆ›å»ºåŒ…å«3ä¸ªæ¨¡å‹è·¯å¾„çš„åˆ—è¡¨\n",
    "\n",
    "MODELS  # æ˜¾ç¤ºæ¨¡å‹è·¯å¾„åˆ—è¡¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c627ee3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:08.740284Z",
     "iopub.status.busy": "2025-06-04T13:56:08.739924Z",
     "iopub.status.idle": "2025-06-04T13:56:08.748130Z",
     "shell.execute_reply": "2025-06-04T13:56:08.747003Z"
    },
    "papermill": {
     "duration": 0.017017,
     "end_time": "2025-06-04T13:56:08.749818",
     "exception": false,
     "start_time": "2025-06-04T13:56:08.732801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prediction(afile):    \n",
    "    global pred  # ä½¿ç”¨å…¨å±€é¢„æµ‹ç»“æœå­—å…¸\n",
    "    path = test_audio_dir + afile + '.ogg'  # æ„å»ºéŸ³é¢‘æ–‡ä»¶å®Œæ•´è·¯å¾„\n",
    "    with torch.inference_mode():  # ä½¿ç”¨æ¨ç†æ¨¡å¼ï¼Œä¸è®¡ç®—æ¢¯åº¦\n",
    "        sig = audio_to_mel(path)  # å°†éŸ³é¢‘è½¬æ¢ä¸ºæ¢…å°”é¢‘è°±\n",
    "        outputs = None  # åˆå§‹åŒ–è¾“å‡ºä¸ºNone\n",
    "        for model in models:  # éå†æ‰€æœ‰æ¨¡å‹\n",
    "            model.eval()  # å°†æ¨¡å‹è®¾ä¸ºè¯„ä¼°æ¨¡å¼\n",
    "            p = model(sig)  # é€šè¿‡æ¨¡å‹è·å–é¢„æµ‹ç»“æœ\n",
    "            p = torch.sigmoid(p['logit']).detach().cpu().numpy()  # åº”ç”¨sigmoidï¼Œè½¬ä¸ºnumpyæ•°ç»„\n",
    "            p = adaptive_power(p, top_k=30, min_exp=1.5, max_exp=3.0)  # åº”ç”¨è‡ªé€‚åº”å¹‚å˜æ¢\n",
    "            if outputs is None: outputs = p  # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªæ¨¡å‹ï¼Œç›´æ¥èµ‹å€¼\n",
    "            else: outputs += p  # å¦åˆ™ç´¯åŠ é¢„æµ‹ç»“æœ\n",
    "            \n",
    "        outputs /= len(models)  # è®¡ç®—æ¨¡å‹å¹³å‡ç»“æœ\n",
    "        chunks = [[] for i in range(12)]  # åˆå§‹åŒ–12ä¸ªåŒºå—çš„åˆ—è¡¨\n",
    "        for i in range(len(chunks)):  # éå†æ¯ä¸ªåŒºå—      \n",
    "            chunk_end_time = (i + 1) * 5  # è®¡ç®—åŒºå—ç»“æŸæ—¶é—´\n",
    "            row_id = afile + '_' + str(chunk_end_time)  # æ„å»ºè¡ŒID\n",
    "            pred['row_id'].append(row_id)  # æ·»åŠ è¡ŒIDåˆ°ç»“æœ\n",
    "            bird_no = 0  # åˆå§‹åŒ–é¸Ÿç±»ç¼–å·\n",
    "            for bird in class_labels:  # éå†æ‰€æœ‰é¸Ÿç±»ç±»åˆ«       \n",
    "                pred[bird].append(outputs[i,bird_no])  # æ·»åŠ è¯¥é¸Ÿç±»çš„é¢„æµ‹æ¦‚ç‡\n",
    "                bird_no += 1  # é¸Ÿç±»ç¼–å·åŠ 1\n",
    "        gc.collect()  # è§¦å‘åƒåœ¾å›æ”¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fa50b3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:08.764451Z",
     "iopub.status.busy": "2025-06-04T13:56:08.764088Z",
     "iopub.status.idle": "2025-06-04T13:56:13.145479Z",
     "shell.execute_reply": "2025-06-04T13:56:13.144283Z"
    },
    "papermill": {
     "duration": 4.390174,
     "end_time": "2025-06-04T13:56:13.147106",
     "exception": false,
     "start_time": "2025-06-04T13:56:08.756932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = []  # åˆå§‹åŒ–æ¨¡å‹åˆ—è¡¨\n",
    "for path in MODELS:  # éå†æ‰€æœ‰æ¨¡å‹è·¯å¾„\n",
    "    model = TimmSED(base_model_name=base_model_name,  # åˆ›å»ºTimmSEDæ¨¡å‹å®ä¾‹\n",
    "               pretrained=pretrained,  # è®¾ç½®æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒ\n",
    "               num_classes=len(class_labels),  # è®¾ç½®ç±»åˆ«æ•°é‡\n",
    "               in_channels=in_channels,  # è®¾ç½®è¾“å…¥é€šé“æ•°\n",
    "               n_mels=n_mels)  # è®¾ç½®æ¢…å°”é¢‘è°±é¢‘æ®µæ•°\n",
    "    model.load_state_dict(torch.load(path, weights_only=True, map_location=torch.device('cpu')))  # åŠ è½½æ¨¡å‹æƒé‡\n",
    "    model.eval()  # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼\n",
    "    models.append(model)  # å°†æ¨¡å‹æ·»åŠ åˆ°åˆ—è¡¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea2b32cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:13.161065Z",
     "iopub.status.busy": "2025-06-04T13:56:13.160592Z",
     "iopub.status.idle": "2025-06-04T13:56:38.336791Z",
     "shell.execute_reply": "2025-06-04T13:56:38.335525Z"
    },
    "papermill": {
     "duration": 25.185337,
     "end_time": "2025-06-04T13:56:38.338867",
     "exception": false,
     "start_time": "2025-06-04T13:56:13.153530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.70228918393453\n"
     ]
    }
   ],
   "source": [
    "pred = {'row_id': []}  # åˆå§‹åŒ–é¢„æµ‹ç»“æœå­—å…¸ï¼ŒåŒ…å«è¡ŒIDé”®\n",
    "for species_code in class_labels:  # éå†æ‰€æœ‰é¸Ÿç±»ç±»åˆ«\n",
    "    pred[species_code] = []  # ä¸ºæ¯ä¸ªé¸Ÿç±»åˆ›å»ºç©ºåˆ—è¡¨\n",
    "    \n",
    "start = time.time()  # è®°å½•å¼€å§‹æ—¶é—´\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:  # åˆ›å»ºçº¿ç¨‹æ± æ‰§è¡Œå™¨ï¼Œæœ€å¤§5ä¸ªçº¿ç¨‹\n",
    "    _ = list(executor.map(prediction, file_list))  # å¹¶è¡Œæ‰§è¡Œé¢„æµ‹å‡½æ•°\n",
    "end_t = time.time()  # è®°å½•ç»“æŸæ—¶é—´\n",
    "\n",
    "if debug == True:  # å¦‚æœæ˜¯è°ƒè¯•æ¨¡å¼\n",
    "    print(700*(end_t - start)/60/debug_num)  # æ‰“å°ä¼°è®¡çš„å®Œæ•´æ•°æ®é›†å¤„ç†æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f8fa122",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:38.360939Z",
     "iopub.status.busy": "2025-06-04T13:56:38.360603Z",
     "iopub.status.idle": "2025-06-04T13:56:38.394778Z",
     "shell.execute_reply": "2025-06-04T13:56:38.393768Z"
    },
    "papermill": {
     "duration": 0.043771,
     "end_time": "2025-06-04T13:56:38.396790",
     "exception": false,
     "start_time": "2025-06-04T13:56:38.353019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(pred, columns = ['row_id'] + class_labels)  # åˆ›å»ºç»“æœæ•°æ®æ¡†ï¼ŒåŒ…å«è¡ŒIDå’Œæ‰€æœ‰é¸Ÿç±»ç±»åˆ«åˆ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe73b181",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:38.411111Z",
     "iopub.status.busy": "2025-06-04T13:56:38.410155Z",
     "iopub.status.idle": "2025-06-04T13:56:39.003829Z",
     "shell.execute_reply": "2025-06-04T13:56:39.002689Z"
    },
    "papermill": {
     "duration": 0.602718,
     "end_time": "2025-06-04T13:56:39.005707",
     "exception": false,
     "start_time": "2025-06-04T13:56:38.402989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.to_csv(\"submission1.csv\", index=False)  # ä¿å­˜ç»“æœä¸ºCSVæ–‡ä»¶ï¼Œä¸åŒ…å«ç´¢å¼•åˆ—\n",
    "\n",
    "sub = pd.read_csv('submission1.csv')  # è¯»å–ä¿å­˜çš„CSVæ–‡ä»¶\n",
    "cols = sub.columns[1:]  # è·å–é™¤è¡ŒIDå¤–çš„æ‰€æœ‰åˆ—å\n",
    "groups = sub['row_id'].str.rsplit('_', n=1).str[0]  # ä»è¡ŒIDä¸­æå–å£°éŸ³æ–‡ä»¶å\n",
    "groups = groups.values  # è½¬æ¢ä¸ºnumpyæ•°ç»„\n",
    "for group in np.unique(groups):  # éå†æ¯ä¸ªå”¯ä¸€çš„å£°éŸ³æ–‡ä»¶\n",
    "    sub_group = sub[group == groups]  # æå–å½“å‰å£°éŸ³æ–‡ä»¶çš„æ‰€æœ‰ç‰‡æ®µ\n",
    "    predictions = sub_group[cols].values  # è·å–é¢„æµ‹å€¼æ•°ç»„\n",
    "    new_predictions = predictions.copy()  # åˆ›å»ºé¢„æµ‹å€¼å‰¯æœ¬\n",
    "    for i in range(1, predictions.shape[0]-1):  # å¤„ç†ä¸­é—´ç‰‡æ®µï¼ˆåº”ç”¨æ»‘åŠ¨çª—å£å¹³æ»‘ï¼‰\n",
    "        new_predictions[i] = (predictions[i-1] * 0.2) + (predictions[i] * 0.6) + (predictions[i+1] * 0.2)  # åŠ æƒå¹³å‡\n",
    "    new_predictions[0] = (predictions[0] * 0.8) + (predictions[1] * 0.2)  # å¤„ç†ç¬¬ä¸€ä¸ªç‰‡æ®µ\n",
    "    new_predictions[-1] = (predictions[-1] * 0.8) + (predictions[-2] * 0.2)  # å¤„ç†æœ€åä¸€ä¸ªç‰‡æ®µ\n",
    "    sub_group[cols] = new_predictions  # æ›´æ–°å­ç»„çš„é¢„æµ‹å€¼\n",
    "    sub[group == groups] = sub_group  # å°†å­ç»„ç»“æœæ”¾å›ä¸»æ•°æ®æ¡†\n",
    "sub.to_csv(\"submission1.csv\", index=False)  # ä¿å­˜å¹³æ»‘åçš„ç»“æœ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147effdd",
   "metadata": {
    "papermill": {
     "duration": 0.005954,
     "end_time": "2025-06-04T13:56:39.018292",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.012338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"color: #6cb4e4;  text-align: center;  padding: 0.25em;  border-top: solid 2.5px #6cb4e4;  border-bottom: solid 2.5px #6cb4e4;  background: -webkit-repeating-linear-gradient(-45deg, #f0f8ff, #f0f8ff 3px,#e9f4ff 3px, #e9f4ff 7px);  background: repeating-linear-gradient(-45deg, #f0f8ff, #f0f8ff 3px,#e9f4ff 3px, #e9f4ff 7px);height:45px;\">\n",
    "<b>\n",
    "ã€Šã€Šã€Šsubmission2(seresnext)ã€‹ã€‹ã€‹\n",
    "</b></h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5151069",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.031760Z",
     "iopub.status.busy": "2025-06-04T13:56:39.031459Z",
     "iopub.status.idle": "2025-06-04T13:56:39.501435Z",
     "shell.execute_reply": "2025-06-04T13:56:39.500363Z"
    },
    "papermill": {
     "duration": 0.478661,
     "end_time": "2025-06-04T13:56:39.503051",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.024390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os  # å¯¼å…¥æ“ä½œç³»ç»Ÿæ¥å£æ¨¡å—\n",
    "import gc  # å¯¼å…¥åƒåœ¾æ”¶é›†æ¨¡å—\n",
    "import warnings  # å¯¼å…¥è­¦å‘Šæ§åˆ¶æ¨¡å—\n",
    "import logging  # å¯¼å…¥æ—¥å¿—æ¨¡å—\n",
    "import time  # å¯¼å…¥æ—¶é—´ç›¸å…³æ¨¡å—\n",
    "from pathlib import Path  # å¯¼å…¥è·¯å¾„å¤„ç†æ¨¡å—\n",
    "import pandas as pd  # å¯¼å…¥æ•°æ®å¤„ç†åº“\n",
    "import soundfile as sf  # å¯¼å…¥éŸ³é¢‘æ–‡ä»¶è¯»å†™æ¨¡å—\n",
    "import torch  # å¯¼å…¥PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶\n",
    "import torch.nn as nn  # å¯¼å…¥ç¥ç»ç½‘ç»œæ¨¡å—\n",
    "import torch.nn.functional as F  # å¯¼å…¥å‡½æ•°å¼æ¥å£\n",
    "import timm  # å¯¼å…¥é¢„è®­ç»ƒæ¨¡å‹åº“\n",
    "from glob import glob  # å¯¼å…¥æ–‡ä»¶è·¯å¾„åŒ¹é…æ¨¡å—\n",
    "import torchaudio  # å¯¼å…¥éŸ³é¢‘å¤„ç†åº“\n",
    "import random  # å¯¼å…¥éšæœºæ•°æ¨¡å—\n",
    "import itertools  # å¯¼å…¥è¿­ä»£å™¨å·¥å…·\n",
    "import concurrent.futures  # å¯¼å…¥å¹¶è¡Œå¤„ç†æ¨¡å—\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # å¿½ç•¥è­¦å‘Šä¿¡æ¯\n",
    "logging.basicConfig(level=logging.ERROR)  # è®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9968aac5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.517368Z",
     "iopub.status.busy": "2025-06-04T13:56:39.516923Z",
     "iopub.status.idle": "2025-06-04T13:56:39.522940Z",
     "shell.execute_reply": "2025-06-04T13:56:39.521972Z"
    },
    "papermill": {
     "duration": 0.015008,
     "end_time": "2025-06-04T13:56:39.524583",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.509575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:  # å®šä¹‰é…ç½®ç±»\n",
    "    \n",
    "    seed = 42  # éšæœºç§å­\n",
    "    print_freq = 100  # æ‰“å°é¢‘ç‡\n",
    "    num_workers = 4  # æ•°æ®åŠ è½½å™¨çš„å·¥ä½œçº¿ç¨‹æ•°\n",
    "\n",
    "    stage = 'train_bce'  # è®­ç»ƒé˜¶æ®µæ ‡è¯†\n",
    "\n",
    "    train_datadir = '/kaggle/input/birdclef-2025/train_audio'  # è®­ç»ƒéŸ³é¢‘ç›®å½•\n",
    "    train_csv = '/kaggle/input/birdclef-2025/train.csv'  # è®­ç»ƒCSVæ–‡ä»¶è·¯å¾„\n",
    "    test_soundscapes = '/kaggle/input/birdclef-2025/test_soundscapes'  # æµ‹è¯•å£°éŸ³æ™¯è§‚ç›®å½•\n",
    "    submission_csv = '/kaggle/input/birdclef-2025/sample_submission.csv'  # æäº¤æ ·ä¾‹æ–‡ä»¶\n",
    "    taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'  # åˆ†ç±»å­¦CSVæ–‡ä»¶è·¯å¾„\n",
    "    model_files = ['/kaggle/input/bird2025-sed-ckpt/sedmodel.pth'  # æ¨¡å‹æ–‡ä»¶è·¯å¾„\n",
    "                  ]\n",
    " \n",
    "    model_name = 'seresnext26t_32x4d'  # æ¨¡å‹åç§°\n",
    "    pretrained = False  # æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡\n",
    "    in_channels = 1  # è¾“å…¥é€šé“æ•°\n",
    "\n",
    "    \n",
    "    SR = 32000  # é‡‡æ ·ç‡\n",
    "    target_duration = 5  # ç›®æ ‡éŸ³é¢‘æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "    train_duration = 10  # è®­ç»ƒéŸ³é¢‘æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "    \n",
    "    \n",
    "    device = 'cpu'  # è®¡ç®—è®¾å¤‡\n",
    "\n",
    "cfg = CFG()  # åˆ›å»ºé…ç½®å¯¹è±¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc09ee15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.538726Z",
     "iopub.status.busy": "2025-06-04T13:56:39.538280Z",
     "iopub.status.idle": "2025-06-04T13:56:39.550605Z",
     "shell.execute_reply": "2025-06-04T13:56:39.549476Z"
    },
    "papermill": {
     "duration": 0.021381,
     "end_time": "2025-06-04T13:56:39.552471",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.531090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading taxonomy data...\n",
      "Number of classes: 206\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using device: {cfg.device}\")  # æ‰“å°æ‰€ä½¿ç”¨çš„è®¡ç®—è®¾å¤‡\n",
    "print(f\"Loading taxonomy data...\")  # æ‰“å°åŠ è½½åˆ†ç±»æ•°æ®çš„ä¿¡æ¯\n",
    "taxonomy_df = pd.read_csv(cfg.taxonomy_csv)  # è¯»å–é¸Ÿç±»åˆ†ç±»æ•°æ®\n",
    "species_ids = taxonomy_df['primary_label'].tolist()  # æå–æ‰€æœ‰é¸Ÿç±»IDåˆ—è¡¨\n",
    "num_classes = len(species_ids)  # è®¡ç®—é¸Ÿç±»ç±»åˆ«æ•°é‡\n",
    "print(f\"Number of classes: {num_classes}\")  # æ‰“å°ç±»åˆ«æ•°é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3fd51d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.566606Z",
     "iopub.status.busy": "2025-06-04T13:56:39.566239Z",
     "iopub.status.idle": "2025-06-04T13:56:39.579710Z",
     "shell.execute_reply": "2025-06-04T13:56:39.578797Z"
    },
    "papermill": {
     "duration": 0.022438,
     "end_time": "2025-06-04T13:56:39.581389",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.558951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):  # å®šä¹‰è®¾ç½®éšæœºç§å­çš„å‡½æ•°\n",
    "    \"\"\"\n",
    "    è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯é‡ç°\n",
    "    \"\"\"\n",
    "    random.seed(seed)  # è®¾ç½®Pythonéšæœºæ¨¡å—çš„ç§å­\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)  # è®¾ç½®Pythonå“ˆå¸Œç§å­\n",
    "    np.random.seed(seed)  # è®¾ç½®NumPyéšæœºç§å­\n",
    "    torch.manual_seed(seed)  # è®¾ç½®PyTorch CPUéšæœºç§å­\n",
    "    torch.cuda.manual_seed(seed)  # è®¾ç½®PyTorchå•GPUéšæœºç§å­\n",
    "    torch.cuda.manual_seed_all(seed)  # è®¾ç½®PyTorchå¤šGPUéšæœºç§å­\n",
    "    torch.backends.cudnn.deterministic = True  # ä½¿cudnnå·ç§¯æ“ä½œç¡®å®šæ€§\n",
    "    torch.backends.cudnn.benchmark = False  # ç¦ç”¨cudnnåŸºå‡†æµ‹è¯•\n",
    "\n",
    "set_seed(cfg.seed)  # ä½¿ç”¨é…ç½®ä¸­çš„ç§å­åˆå§‹åŒ–éšæœºæ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d97e381",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.595707Z",
     "iopub.status.busy": "2025-06-04T13:56:39.595341Z",
     "iopub.status.idle": "2025-06-04T13:56:39.605390Z",
     "shell.execute_reply": "2025-06-04T13:56:39.604427Z"
    },
    "papermill": {
     "duration": 0.019114,
     "end_time": "2025-06-04T13:56:39.607090",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.587976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttBlockV2(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, activation=\"linear\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == \"linear\":\n",
    "            return x\n",
    "        elif self.activation == \"sigmoid\":\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.0)\n",
    "\n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.0)\n",
    "    bn.weight.data.fill_(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65d6c282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.622132Z",
     "iopub.status.busy": "2025-06-04T13:56:39.621775Z",
     "iopub.status.idle": "2025-06-04T13:56:39.643285Z",
     "shell.execute_reply": "2025-06-04T13:56:39.642156Z"
    },
    "papermill": {
     "duration": 0.031308,
     "end_time": "2025-06-04T13:56:39.645163",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.613855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BirdCLEFModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        taxonomy_df = pd.read_csv('/kaggle/input/birdclef-2025/taxonomy.csv')\n",
    "        self.num_classes = len(taxonomy_df)\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(cfg['n_mels'])\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            cfg['model_name'],\n",
    "            pretrained=False,\n",
    "            in_chans=cfg['in_channels'],\n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.2,\n",
    "        )\n",
    "\n",
    "        layers = list(self.backbone.children())[:-2]\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "        \n",
    "        if \"efficientnet\" in self.cfg['model_name']:\n",
    "            backbone_out = self.backbone.classifier.in_features\n",
    "        elif \"eca\" in self.cfg['model_name']:\n",
    "            backbone_out = self.backbone.head.fc.in_features\n",
    "        elif \"res\" in self.cfg['model_name']:\n",
    "            backbone_out = self.backbone.fc.in_features\n",
    "        else:\n",
    "            backbone_out = self.backbone.num_features\n",
    "            \n",
    "        \n",
    "        self.fc1 = nn.Linear(backbone_out, backbone_out, bias=True)\n",
    "        self.att_block = AttBlockV2(backbone_out, self.num_classes, activation=\"sigmoid\")\n",
    "\n",
    "        self.melspec_transform = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=self.cfg['SR'],\n",
    "            hop_length=self.cfg['hop_length'],\n",
    "            n_mels=self.cfg['n_mels'],\n",
    "            f_min=self.cfg['f_min'],\n",
    "            f_max=self.cfg['f_max'],\n",
    "            n_fft=self.cfg['n_fft'],\n",
    "            pad_mode=\"constant\",\n",
    "            norm=\"slaney\",\n",
    "            onesided=True,\n",
    "            mel_scale=\"htk\",\n",
    "        )\n",
    "        if self.cfg['device'] == \"cuda\":\n",
    "            self.melspec_transform = self.melspec_transform.cuda()\n",
    "        else:\n",
    "            self.melspec_transform = self.melspec_transform.cpu()\n",
    "\n",
    "        self.db_transform = torchaudio.transforms.AmplitudeToDB(\n",
    "            stype=\"power\", top_db=80\n",
    "        )\n",
    "\n",
    "\n",
    "    def extract_feature(self,x):\n",
    "        x = x.permute((0, 1, 3, 2))\n",
    "        frames_num = x.shape[2]\n",
    "        \n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "        \n",
    "        # if self.training:\n",
    "        #    x = self.spec_augmenter(x)\n",
    "        \n",
    "        x = x.transpose(2, 3)\n",
    "        # (batch_size, channels, freq, frames)\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        # (batch_size, channels, frames)\n",
    "        x = torch.mean(x, dim=2)\n",
    "        \n",
    "        # channel smoothing\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "        \n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return x, frames_num\n",
    "        \n",
    "    @torch.cuda.amp.autocast(enabled=False)\n",
    "    def transform_to_spec(self, audio):\n",
    "\n",
    "        audio = audio.float()\n",
    "        \n",
    "        spec = self.melspec_transform(audio)\n",
    "        spec = self.db_transform(spec)\n",
    "\n",
    "        if self.cfg['normal'] == 80:\n",
    "            spec = (spec + 80) / 80\n",
    "        elif self.cfg['normal'] == 255:\n",
    "            spec = spec / 255\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "                \n",
    "        if self.cfg['in_channels'] == 3:\n",
    "            spec = image_delta(spec)\n",
    "        \n",
    "        return spec\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = self.transform_to_spec(x)\n",
    "\n",
    "        x, frames_num = self.extract_feature(x)\n",
    "        \n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n",
    "        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        return torch.logit(clipwise_output)\n",
    "\n",
    "    def infer(self, x, tta_delta=2):\n",
    "        with torch.no_grad():\n",
    "            x = self.transform_to_spec(x)\n",
    "        x,_ = self.extract_feature(x)\n",
    "        time_att = torch.tanh(self.att_block.att(x))\n",
    "        feat_time = x.size(-1)\n",
    "        start = (\n",
    "            feat_time / 2 - feat_time * (self.cfg['infer_duration'] / self.cfg['duration_train']) / 2\n",
    "        )\n",
    "        end = start + feat_time * (self.cfg['infer_duration'] / self.cfg['duration_train'])\n",
    "        start = int(start)\n",
    "        end = int(end)\n",
    "        pred = self.attention_infer(start,end,x,time_att)\n",
    "\n",
    "        start_minus = max(0, start-tta_delta)\n",
    "        end_minus=end-tta_delta\n",
    "        pred_minus = self.attention_infer(start_minus,end_minus,x,time_att)\n",
    "\n",
    "        start_plus = start+tta_delta\n",
    "        end_plus=min(feat_time, end+tta_delta)\n",
    "        pred_plus = self.attention_infer(start_plus,end_plus,x,time_att)\n",
    "\n",
    "        pred = 0.5*pred + 0.25*pred_minus + 0.25*pred_plus\n",
    "        return pred\n",
    "        \n",
    "    def attention_infer(self,start,end,x,time_att):\n",
    "        feat = x[:, :, start:end]\n",
    "        # att = torch.softmax(time_att[:, :, start:end], dim=-1)\n",
    "        #             print(feat_time, start, end)\n",
    "        #             print(att_a.sum(), att.sum(), time_att.shape)\n",
    "        framewise_pred = torch.sigmoid(self.att_block.cla(feat))\n",
    "        framewise_pred_max = framewise_pred.max(dim=2)[0]\n",
    "        # clipwise_output = torch.sum(framewise_pred * att, dim=-1)\n",
    "        #logits = torch.sum(\n",
    "        #    self.att_block.cla(feat) * att,\n",
    "        #    dim=-1,\n",
    "        #)\n",
    "\n",
    "        # return clipwise_output\n",
    "        return framewise_pred_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ba6ddcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.659552Z",
     "iopub.status.busy": "2025-06-04T13:56:39.659186Z",
     "iopub.status.idle": "2025-06-04T13:56:39.668906Z",
     "shell.execute_reply": "2025-06-04T13:56:39.667745Z"
    },
    "papermill": {
     "duration": 0.019029,
     "end_time": "2025-06-04T13:56:39.670693",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.651664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_sample(path, cfg):\n",
    "    audio, orig_sr = sf.read(path, dtype=\"float32\")\n",
    "    seconds = []\n",
    "    audio_length = cfg.SR * cfg.target_duration\n",
    "    step = audio_length\n",
    "    for i in range(audio_length, len(audio) + step, step):\n",
    "        start = max(0, i - audio_length)\n",
    "        end = start + audio_length\n",
    "        if end > len(audio):\n",
    "            pass\n",
    "        else:\n",
    "            seconds.append(int(end/cfg.SR))\n",
    "\n",
    "    audio = np.concatenate([audio,audio,audio])\n",
    "    audios = []\n",
    "    for i,second in enumerate(seconds):\n",
    "        end_seconds = int(second)\n",
    "        start_seconds = int(end_seconds - cfg.target_duration)\n",
    "    \n",
    "        end_index = int(cfg.SR * (end_seconds + (cfg.train_duration - cfg.target_duration) / 2) ) + len(audio) // 3\n",
    "        start_index = int(cfg.SR * (start_seconds - (cfg.train_duration - cfg.target_duration) / 2) ) + len(audio) // 3\n",
    "        end_pad = int(cfg.SR * (cfg.train_duration - cfg.target_duration) / 2) \n",
    "        start_pad = int(cfg.SR * (cfg.train_duration - cfg.target_duration) / 2) \n",
    "        y = audio[start_index:end_index].astype(np.float32)\n",
    "        if i==0:\n",
    "            y[:start_pad] = 0\n",
    "        elif i==(len(seconds)-1):\n",
    "            y[-end_pad:] = 0\n",
    "        audios.append(y)\n",
    "\n",
    "    return audios\n",
    "\n",
    "def sigmoid(x):\n",
    "    s = 1 / (1 + np.exp(-x))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "104a3c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.684882Z",
     "iopub.status.busy": "2025-06-04T13:56:39.684588Z",
     "iopub.status.idle": "2025-06-04T13:56:39.696640Z",
     "shell.execute_reply": "2025-06-04T13:56:39.695577Z"
    },
    "papermill": {
     "duration": 0.021099,
     "end_time": "2025-06-04T13:56:39.698241",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.677142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_model_files(cfg):\n",
    "    \"\"\"\n",
    "    Find all .pth model files in the specified model directory\n",
    "    \"\"\"\n",
    "    model_files = []\n",
    "    \n",
    "    model_dir = Path(cfg.model_path)\n",
    "    \n",
    "    for path in model_dir.glob('**/*.pth'):\n",
    "        model_files.append(str(path))\n",
    "    \n",
    "    return model_files\n",
    "\n",
    "def load_models(cfg, num_classes):\n",
    "    \"\"\"\n",
    "    Load all found model files and prepare them for ensemble\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    \n",
    "    # model_files = find_model_files(cfg)\n",
    "    model_files = cfg.model_files\n",
    "    \n",
    "    if not model_files:\n",
    "        print(f\"Warning: No model files found under {cfg.model_path}!\")\n",
    "        return models\n",
    "    \n",
    "    print(f\"Found a total of {len(model_files)} model files.\")\n",
    "    \n",
    "    for i, model_path in enumerate(model_files):\n",
    "        try:\n",
    "            print(f\"Loading model: {model_path}\")\n",
    "            checkpoint = torch.load(model_path, map_location=torch.device(cfg.device), weights_only=False)\n",
    "            cfg_temp = checkpoint['cfg']\n",
    "            cfg_temp['device'] = cfg.device\n",
    "            \n",
    "            model = BirdCLEFModel(cfg_temp)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            model = model.to(cfg.device)\n",
    "            model.eval()\n",
    "            model.zero_grad()\n",
    "            model.half().float()\n",
    "            \n",
    "            models.append(model)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {model_path}: {e}\")\n",
    "    \n",
    "    return models\n",
    "\n",
    "def predict_on_spectrogram(audio_path, models, cfg, species_ids):\n",
    "    \"\"\"Process a single audio file and predict species presence for each 5-second segment\"\"\"\n",
    "    audio_path = str(audio_path)\n",
    "    predictions = []\n",
    "    row_ids = []\n",
    "    soundscape_id = Path(audio_path).stem\n",
    "\n",
    "    print(f\"Processing {soundscape_id}\")\n",
    "    audio_data = load_sample(audio_path, cfg)\n",
    "    for segment_idx, audio_input in enumerate(audio_data):\n",
    "        \n",
    "        end_time_sec = (segment_idx + 1) * cfg.target_duration\n",
    "        row_id = f\"{soundscape_id}_{end_time_sec}\"\n",
    "        row_ids.append(row_id)\n",
    "        \n",
    "        mel_spec = torch.tensor(audio_input, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        mel_spec = mel_spec.to(cfg.device)\n",
    "        \n",
    "        if len(models) == 1:\n",
    "            with torch.no_grad():\n",
    "                outputs = models[0].infer(mel_spec)\n",
    "                final_preds = outputs.squeeze()\n",
    "                # final_preds = torch.sigmoid(outputs).cpu().numpy().squeeze()\n",
    "\n",
    "        else:\n",
    "            segment_preds = []\n",
    "            for model in models:\n",
    "                with torch.no_grad():\n",
    "                    outputs = model.infer(mel_spec)\n",
    "                    probs = outputs.squeeze()\n",
    "                    # probs = torch.sigmoid(outputs).cpu().numpy().squeeze()\n",
    "                    segment_preds.append(probs)\n",
    "\n",
    "            \n",
    "            final_preds = np.mean(segment_preds, axis=0)\n",
    "                \n",
    "        predictions.append(final_preds)\n",
    "\n",
    "    predictions = np.stack(predictions,axis=0)\n",
    "    \n",
    "    return row_ids, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1776992c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.712834Z",
     "iopub.status.busy": "2025-06-04T13:56:39.712512Z",
     "iopub.status.idle": "2025-06-04T13:56:39.725762Z",
     "shell.execute_reply": "2025-06-04T13:56:39.724880Z"
    },
    "papermill": {
     "duration": 0.022395,
     "end_time": "2025-06-04T13:56:39.727353",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.704958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_inference(cfg, models, species_ids):\n",
    "    \"\"\"Run inference on all test soundscapes\"\"\"\n",
    "    test_files = list(Path(cfg.test_soundscapes).glob('*.ogg'))\n",
    "    if len(test_files) == 0:\n",
    "        test_files = sorted(glob(str(Path('/kaggle/input/birdclef-2025/train_soundscapes') / '*.ogg')))[:10]\n",
    "    \n",
    "    print(f\"Found {len(test_files)} test soundscapes\")\n",
    "\n",
    "    all_row_ids = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        results = list(\n",
    "        executor.map(\n",
    "            predict_on_spectrogram,\n",
    "            test_files,\n",
    "            itertools.repeat(models),\n",
    "            itertools.repeat(cfg),\n",
    "            itertools.repeat(species_ids)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for rids, preds in results:\n",
    "        all_row_ids.extend(rids)\n",
    "        all_predictions.extend(preds)\n",
    "    \n",
    "    return all_row_ids, all_predictions\n",
    "\n",
    "def create_submission(row_ids, predictions, species_ids, cfg):\n",
    "    \"\"\"Create submission dataframe\"\"\"\n",
    "    print(\"Creating submission dataframe...\")\n",
    "\n",
    "    submission_dict = {'row_id': row_ids}\n",
    "    \n",
    "    for i, species in enumerate(species_ids):\n",
    "        submission_dict[species] = [pred[i] for pred in predictions]\n",
    "\n",
    "    submission_df = pd.DataFrame(submission_dict)\n",
    "\n",
    "    submission_df.set_index('row_id', inplace=True)\n",
    "\n",
    "    sample_sub = pd.read_csv(cfg.submission_csv, index_col='row_id')\n",
    "\n",
    "    missing_cols = set(sample_sub.columns) - set(submission_df.columns)\n",
    "    if missing_cols:\n",
    "        print(f\"Warning: Missing {len(missing_cols)} species columns in submission\")\n",
    "        for col in missing_cols:\n",
    "            submission_df[col] = 0.0\n",
    "\n",
    "    submission_df = submission_df[sample_sub.columns]\n",
    "\n",
    "    submission_df = submission_df.reset_index()\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "\n",
    "def smooth_submission(submission_path):\n",
    "        \"\"\"\n",
    "        Post-process the submission CSV by smoothing predictions to enforce temporal consistency.\n",
    "        \n",
    "        For each soundscape (grouped by the file name part of 'row_id'), each row's predictions\n",
    "        are averaged with those of its neighbors using defined weights.\n",
    "        \n",
    "        :param submission_path: Path to the submission CSV file.\n",
    "        \"\"\"\n",
    "        print(\"Smoothing submission predictions...\")\n",
    "        sub = pd.read_csv(submission_path)\n",
    "        cols = sub.columns[1:]\n",
    "        groups = sub['row_id'].str.rsplit('_', n=1).str[0].values\n",
    "        unique_groups = np.unique(groups)\n",
    "        for group in unique_groups:\n",
    "            idx = np.where(groups == group)[0]\n",
    "            sub_group = sub.iloc[idx].copy()\n",
    "            predictions = sub_group[cols].values\n",
    "            new_predictions = predictions.copy()\n",
    "            if predictions.shape[0] > 2:\n",
    "                new_predictions[0] = (predictions[0]*0.6 + predictions[1]*0.3 + predictions[2]*0.1)\n",
    "                new_predictions[1] = (predictions[0]*0.2 + predictions[1]*0.6 + predictions[2]*0.2)\n",
    "                for i in range(2, predictions.shape[0]-2):\n",
    "                    new_predictions[i] = (predictions[i-2]*0.1 + predictions[i-1]*0.2 + predictions[i]*0.4 + predictions[i+1]*0.2 + predictions[i+2]*0.1)\n",
    "                new_predictions[-2] = (predictions[-3]*0.2 + predictions[-2]*0.6 + predictions[-1]*0.2)\n",
    "                new_predictions[-1] = (predictions[-3]*0.1 + predictions[-2]*0.3 + predictions[-1]*0.6)\n",
    "            sub.iloc[idx, 1:] = new_predictions\n",
    "        sub.to_csv(submission_path, index=False)\n",
    "        print(f\"Smoothed submission saved to {submission_path}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78d60615",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.742128Z",
     "iopub.status.busy": "2025-06-04T13:56:39.741133Z",
     "iopub.status.idle": "2025-06-04T13:56:39.747558Z",
     "shell.execute_reply": "2025-06-04T13:56:39.746630Z"
    },
    "papermill": {
     "duration": 0.015216,
     "end_time": "2025-06-04T13:56:39.749050",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.733834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():  # å®šä¹‰ä¸»å‡½æ•°\n",
    "    start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´\n",
    "    print(\"Starting BirdCLEF-2025 inference...\")  # æ‰“å°å¼€å§‹æ¨ç†çš„ä¿¡æ¯\n",
    "\n",
    "    models = load_models(cfg, num_classes)  # åŠ è½½æ¨¡å‹\n",
    "    \n",
    "    if not models:  # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ¨¡å‹\n",
    "        print(\"No models found! Please check model paths.\")  # æ‰“å°é”™è¯¯ä¿¡æ¯\n",
    "        return  # æå‰è¿”å›\n",
    "    \n",
    "    print(f\"Model usage: {'Single model' if len(models) == 1 else f'Ensemble of {len(models)} models'}\")  # æ‰“å°æ¨¡å‹ä½¿ç”¨æƒ…å†µ\n",
    "\n",
    "    row_ids, predictions = run_inference(cfg, models, species_ids)  # è¿è¡Œæ¨ç†è·å–ç»“æœ\n",
    "\n",
    "    submission_df = create_submission(row_ids, predictions, species_ids, cfg)  # åˆ›å»ºæäº¤æ•°æ®æ¡†\n",
    "\n",
    "    submission_path = 'submission.csv'  # è®¾ç½®æäº¤æ–‡ä»¶è·¯å¾„\n",
    "    submission_df.to_csv(submission_path, index=False)  # ä¿å­˜æäº¤æ–‡ä»¶\n",
    "    print(f\"Submission saved to {submission_path}\")  # æ‰“å°ä¿å­˜ä¿¡æ¯\n",
    "\n",
    "    smooth_submission(submission_path)  # å¯¹æäº¤ç»“æœè¿›è¡Œå¹³æ»‘å¤„ç†\n",
    "    \n",
    "    end_time = time.time()  # è®°å½•ç»“æŸæ—¶é—´\n",
    "    print(f\"Inference completed in {(end_time - start_time)/60:.2f} minutes\")  # æ‰“å°å®Œæˆæ—¶é—´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af2a842d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:56:39.762994Z",
     "iopub.status.busy": "2025-06-04T13:56:39.762685Z",
     "iopub.status.idle": "2025-06-04T13:57:15.350718Z",
     "shell.execute_reply": "2025-06-04T13:57:15.349783Z"
    },
    "papermill": {
     "duration": 35.596804,
     "end_time": "2025-06-04T13:57:15.352214",
     "exception": false,
     "start_time": "2025-06-04T13:56:39.755410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting BirdCLEF-2025 inference...\n",
      "Found a total of 1 model files.\n",
      "Loading model: /kaggle/input/bird2025-sed-ckpt/sedmodel.pth\n",
      "Model usage: Single model\n",
      "Found 10 test soundscapes\n",
      "Processing H02_20230420_074000\n",
      "Processing H02_20230420_112000\n",
      "Processing H02_20230420_154500\n",
      "Processing H02_20230420_164000\n",
      "Processing H02_20230420_223500\n",
      "Processing H02_20230421_093000\n",
      "Processing H02_20230421_113500\n",
      "Processing H02_20230421_170000\n",
      "Processing H02_20230421_190500\n",
      "Processing H02_20230421_233500\n",
      "Creating submission dataframe...\n",
      "Submission saved to submission.csv\n",
      "Smoothing submission predictions...\n",
      "Smoothed submission saved to submission.csv\n",
      "Inference completed in 0.59 minutes\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":  # å¦‚æœä½œä¸ºä¸»ç¨‹åºè¿è¡Œ\n",
    "    main()  # æ‰§è¡Œä¸»å‡½æ•°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec755df",
   "metadata": {
    "papermill": {
     "duration": 0.007111,
     "end_time": "2025-06-04T13:57:15.366210",
     "exception": false,
     "start_time": "2025-06-04T13:57:15.359099",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style=\"color: #6cb4e4;  text-align: center;  padding: 0.25em;  border-top: solid 2.5px #6cb4e4;  border-bottom: solid 2.5px #6cb4e4;  background: -webkit-repeating-linear-gradient(-45deg, #f0f8ff, #f0f8ff 3px,#e9f4ff 3px, #e9f4ff 7px);  background: repeating-linear-gradient(-45deg, #f0f8ff, #f0f8ff 3px,#e9f4ff 3px, #e9f4ff 7px);height:45px;\">\n",
    "<b>\n",
    "ã€Šã€Šã€Šæœ€ç»ˆèåˆã€‹ã€‹ã€‹\n",
    "</b></h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72b2b97f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:57:15.381397Z",
     "iopub.status.busy": "2025-06-04T13:57:15.381008Z",
     "iopub.status.idle": "2025-06-04T13:57:15.385596Z",
     "shell.execute_reply": "2025-06-04T13:57:15.384510Z"
    },
    "papermill": {
     "duration": 0.014155,
     "end_time": "2025-06-04T13:57:15.387352",
     "exception": false,
     "start_time": "2025-06-04T13:57:15.373197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------- #\n",
    "# [é‡è¦]\n",
    "# * èåˆæƒé‡\n",
    "# ------------------------------------------- #\n",
    "# æƒé‡è®¾ç½® sub_w=[0.75, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b69a4201",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:57:15.402884Z",
     "iopub.status.busy": "2025-06-04T13:57:15.402479Z",
     "iopub.status.idle": "2025-06-04T13:57:15.407564Z",
     "shell.execute_reply": "2025-06-04T13:57:15.406548Z"
    },
    "papermill": {
     "duration": 0.014954,
     "end_time": "2025-06-04T13:57:15.409480",
     "exception": false,
     "start_time": "2025-06-04T13:57:15.394526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list_TARGETs = sorted(os.listdir('/kaggle/input/birdclef-2025/train_audio/'))\n",
    "# list_targets_0 = [f'{TARGET} 0' for TARGET in list_TARGETs]\n",
    "# list_targets_1 = [f'{TARGET} 1' for TARGET in list_TARGETs]\n",
    "\n",
    "# df0 = pd.read_csv(\"/kaggle/working/submission.csv\")\n",
    "# df1 = pd.read_csv(\"/kaggle/working/submission1.csv\")\n",
    "\n",
    "# df0 = df0.rename(columns={TARGET : f'{TARGET} 0' for TARGET in list_TARGETs})\n",
    "# df1 = df1.rename(columns={TARGET : f'{TARGET} 1' for TARGET in list_TARGETs})\n",
    "\n",
    "# dfs = pd.merge(df0,df1,on=['row_id'])\n",
    "\n",
    "# for i in range(len(list_TARGETs)):\n",
    "#     dfs[list_TARGETs[i]] = dfs[list_targets_0[i]]*sub_w[0] + sub_w[1]*dfs[list_targets_1[i]]\n",
    "             \n",
    "# for col0,col1 in zip(list_targets_0, list_targets_1):\n",
    "#     del dfs[col0]\n",
    "#     del dfs[col1]\n",
    "    \n",
    "    \n",
    "# dfs.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60de7790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:57:15.425757Z",
     "iopub.status.busy": "2025-06-04T13:57:15.425391Z",
     "iopub.status.idle": "2025-06-04T13:57:16.590291Z",
     "shell.execute_reply": "2025-06-04T13:57:16.589162Z"
    },
    "papermill": {
     "duration": 1.175154,
     "end_time": "2025-06-04T13:57:16.592085",
     "exception": false,
     "start_time": "2025-06-04T13:57:15.416931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.special import logit, expit  # å¯¼å…¥ç‰¹æ®Šå‡½æ•°logitå’Œexpitï¼ˆé€†logitï¼‰\n",
    "\n",
    "list_TARGETs = sorted(os.listdir('/kaggle/input/birdclef-2025/train_audio/'))  # è·å–å¹¶æ’åºæ‰€æœ‰é¸Ÿç±»æ ‡ç­¾\n",
    "\n",
    "df0 = pd.read_csv(\"/kaggle/working/submission.csv\")  # è¯»å–ç¬¬ä¸€ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ\n",
    "df1 = pd.read_csv(\"/kaggle/working/submission1.csv\")  # è¯»å–ç¬¬äºŒä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ\n",
    "\n",
    "# ä¿è¯åˆ—åä¸€è‡´\n",
    "for TARGET in list_TARGETs:  # éå†æ‰€æœ‰é¸Ÿç±»æ ‡ç­¾\n",
    "    if f'{TARGET} 0' in df0.columns:  # å¦‚æœåˆ—åå¸¦æœ‰åç¼€\n",
    "        df0[TARGET] = df0[f'{TARGET} 0']  # è§„èŒƒåŒ–åˆ—å\n",
    "    if f'{TARGET} 1' in df1.columns:  # å¦‚æœåˆ—åå¸¦æœ‰åç¼€\n",
    "        df1[TARGET] = df1[f'{TARGET} 1']  # è§„èŒƒåŒ–åˆ—å\n",
    "\n",
    "cols = [col for col in df0.columns if col != 'row_id']  # è·å–é™¤è¡ŒIDå¤–çš„æ‰€æœ‰åˆ—å\n",
    "\n",
    "blend = df0[['row_id']].copy()  # åˆ›å»ºä»…å«è¡ŒIDçš„æ–°æ•°æ®æ¡†\n",
    "for col in cols:  # éå†æ‰€æœ‰é¸Ÿç±»åˆ—\n",
    "    # åœ¨å¯¹æ•°ç©ºé—´ä¸­åŠ æƒèåˆï¼Œé˜²æ­¢æç«¯æ¦‚ç‡å¯¼è‡´logitæº¢å‡º\n",
    "    blend[col] = expit(0.75*logit(df0[col].clip(1e-6, 1-1e-6)) + 0.25*logit(df1[col].clip(1e-6, 1-1e-6)))\n",
    "blend.to_csv(\"submission.csv\", index=False)  # ä¿å­˜èåˆåçš„ç»“æœæ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9894d4cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T13:57:16.607753Z",
     "iopub.status.busy": "2025-06-04T13:57:16.607438Z",
     "iopub.status.idle": "2025-06-04T13:57:16.960819Z",
     "shell.execute_reply": "2025-06-04T13:57:16.959633Z"
    },
    "papermill": {
     "duration": 0.362976,
     "end_time": "2025-06-04T13:57:16.962565",
     "exception": false,
     "start_time": "2025-06-04T13:57:16.599589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np  # å¯¼å…¥æ•°å€¼è®¡ç®—åº“\n",
    "import pandas as pd  # å¯¼å…¥æ•°æ®å¤„ç†åº“\n",
    "\n",
    "# é¸Ÿç±»å…±ç°è°ƒæ•´\n",
    "num_classes = len(list_TARGETs)  # è·å–é¸Ÿç±»ç±»åˆ«æ•°é‡\n",
    "co_matrix = np.eye(num_classes)  # åˆ›å»ºå•ä½çŸ©é˜µä½œä¸ºå…±ç°çŸ©é˜µï¼ˆå¯ä»¥ç”¨å®é™…ç»Ÿè®¡çš„å…±ç°æ•°æ®æ›¿æ¢ï¼‰\n",
    "\n",
    "def co_occurrence_boost(sub_path, co_matrix, threshold=0.7):  # å®šä¹‰åŸºäºå…±ç°çš„é¢„æµ‹å¢å¼ºå‡½æ•°\n",
    "    sub = pd.read_csv(sub_path)  # è¯»å–æäº¤æ–‡ä»¶\n",
    "    cols = [col for col in sub.columns if col != 'row_id']  # è·å–æ‰€æœ‰é¸Ÿç±»åˆ—å\n",
    "    preds = sub[cols].values  # æå–é¢„æµ‹å€¼æ•°ç»„\n",
    "    boosted = preds.copy()  # åˆ›å»ºé¢„æµ‹å€¼çš„å‰¯æœ¬\n",
    "    for i in range(preds.shape[1]):  # éå†æ¯ä¸ªé¸Ÿç±»ç±»åˆ«\n",
    "        high_idx = preds[:, i] > threshold  # æ‰¾å‡ºé«˜ç½®ä¿¡åº¦é¢„æµ‹\n",
    "        for j in range(preds.shape[1]):  # éå†æ¯ä¸ªé¸Ÿç±»ç±»åˆ«\n",
    "            if i != j:  # å¦‚æœä¸æ˜¯åŒä¸€ä¸ªç±»åˆ«\n",
    "                boosted[high_idx, j] += preds[high_idx, i] * co_matrix[i, j]  # åŸºäºå…±ç°çŸ©é˜µå¢å¼ºé¢„æµ‹\n",
    "    boosted = np.clip(boosted, 0, 1)  # å°†å€¼é™åˆ¶åœ¨0åˆ°1ä¹‹é—´\n",
    "    sub[cols] = boosted  # æ›´æ–°æ•°æ®æ¡†ä¸­çš„é¢„æµ‹å€¼\n",
    "    sub.to_csv(sub_path, index=False)  # ä¿å­˜æ›´æ–°åçš„é¢„æµ‹ç»“æœ\n",
    "\n",
    "co_occurrence_boost(\"submission.csv\", co_matrix, threshold=0.7)  # åº”ç”¨å…±ç°å¢å¼ºåˆ°æœ€ç»ˆç»“æœ"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "sourceId": 91844,
     "sourceType": "competition"
    },
    {
     "datasetId": 7430593,
     "sourceId": 11828260,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7459867,
     "sourceId": 11870659,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 98.342347,
   "end_time": "2025-06-04T13:57:20.259024",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-04T13:55:41.916677",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
